# Belly Rubb

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

This data science project analyzes customer ordering patterns at a local restaurant using data collected through Square. The goal is to uncover key behavioral trends and build a predictive model to forecast daily sales. The project simulates a real-world workflow by incorporating automated data pipelines, feature engineering, machine learning modeling, and dashboard reporting.

## ğŸ” Project Objectives

- Analyze customer behavior to understand why sales are higher on certain days or during specific time periods.
- Identify patterns related to day of week, time of day, promotions, or external factors (e.g. holidays, weather).
- Build a predictive model to forecast daily sales volume.
- Create a lightweight automated pipeline for continuous model updates and insights delivery.
- Develop an interactive dashboard for non-technical stakeholders.

## Project Organization

```
â”œâ”€â”€ LICENSE            <- Open-source license if one is chosen
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â”œâ”€â”€ docs               <- A default mkdocs project; see www.mkdocs.org for details
â”‚
â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for 
â”‚                         belly_rubb and configuration for tools like black
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip freeze > requirements.txt`
â”‚
â”œâ”€â”€ setup.cfg          <- Configuration file for flake8
â”‚
â””â”€â”€ belly_rubb   <- Source code for use in this project.
    â”‚
    â”œâ”€â”€ __init__.py             <- Makes belly_rubb a Python module
    â”‚
    â”œâ”€â”€ config.py               <- Store useful variables and configuration
    â”‚
    â”œâ”€â”€ dataset.py              <- Scripts to download or generate data
    â”‚
    â”œâ”€â”€ features.py             <- Code to create features for modeling
    â”‚
    â”œâ”€â”€ modeling                
    â”‚   â”œâ”€â”€ __init__.py 
    â”‚   â”œâ”€â”€ predict.py          <- Code to run model inference with trained models          
    â”‚   â””â”€â”€ train.py            <- Code to train models
    â”‚
    â””â”€â”€ plots.py                <- Code to create visualizations
```
---

## âš™ï¸ Features & Tools

| Component              | Tool / Library                      |
|------------------------|-------------------------------------|
| Data Source            | Square (CSV/API)                    |
| Language               | Python                              |
| Data Storage           | SQLite (optionally PostgreSQL/Supabase) |
| Data Pipeline          | `schedule`, `cron`, or `Airflow`    |
| EDA & Visualization    | pandas, matplotlib, seaborn         |
| Machine Learning       | scikit-learn, XGBoost               |
| Deployment             | Streamlit                           |
| Version Control        | Git + GitHub                        |

---

## ğŸ“ˆ Key Insights (Preview)

- Sales peak on [X] and dip on [Y].
- Average order value increases during [time period].
- [Specific product or category] drives the most consistent revenue.
- Predictive model achieves an MAE of [value], helping forecast sales with [accuracy]%.

*Note: Final insights will be shared after model evaluation is complete.*

---

## ğŸš€ How to Run

1. Clone the repository:
    ```bash
    git clone https://github.com/yourusername/restaurant-sales-prediction.git
    cd restaurant-sales-prediction
    ```
2. Set up the Environment:
    ```bash
    conda env create -f environment.yml
    conda activate belly_rubb
    ```
3. Run the Pipeline
   ```bash
    # Run data processing scripts
    python src/data/dataset.py

    # Train the model
    python src/models/train_model.py
    ```
4. Launch the Dashboard
    
--------

