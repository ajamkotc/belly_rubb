# Belly Rubb

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

This data science project analyzes customer ordering patterns at a local restaurant using data collected through Square. The goal is to uncover key behavioral trends and build a predictive model to forecast daily sales. The project simulates a real-world workflow by incorporating automated data pipelines, feature engineering, machine learning modeling, and dashboard reporting.

## üîç Project Objectives

- Analyze customer behavior to understand why sales are higher on certain days or during specific time periods.
- Identify patterns related to day of week, time of day, promotions, or external factors (e.g. holidays, weather).
- Build a predictive model to forecast daily sales volume.
- Create a lightweight automated pipeline for continuous model updates and insights delivery.
- Develop an interactive dashboard for non-technical stakeholders.

## Project Organization

```
‚îú‚îÄ‚îÄ LICENSE                     <- Open-source license if one is chosen
|
‚îú‚îÄ‚îÄ Makefile                    <- Makefile with convenience commands.
|
‚îú‚îÄ‚îÄ README.md                   <- The top-level README for developers using this project.
|
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ external                <- Data from third party sources.
‚îÇ   ‚îú‚îÄ‚îÄ interim                 <- Intermediate data that has been transformed.
‚îÇ   ‚îú‚îÄ‚îÄ processed               <- The final, canonical data sets for modeling.
‚îÇ   ‚îî‚îÄ‚îÄ raw                     <- The original, immutable data dump.
|
‚îÇ‚îÄ‚îÄ app
|   ‚îú‚îÄ‚îÄ config.py               <- Store useful variables and configuration.
|   ‚îú‚îÄ‚îÄ db_models.py            <- ORM model for 'access_tokens' table.
|   ‚îú‚îÄ‚îÄ db.py                   <- SQLAlchemy database engine setup.
|   ‚îú‚îÄ‚îÄ pkce_flow.py            <- OAUTH2 PKCE flow.
‚îÇ   ‚îî‚îÄ‚îÄ templates
|       ‚îú‚îÄ‚îÄ callback.html       <- HTML template for callback success page.
|       ‚îî‚îÄ‚îÄ home.html           <- HTML template for homepage.
|
‚îú‚îÄ‚îÄ docs                        <- A default mkdocs project; see www.mkdocs.org for details
‚îÇ
‚îú‚îÄ‚îÄ models                      <- Trained and serialized models.
‚îÇ
‚îú‚îÄ‚îÄ notebooks                   <- Jupyter notebooks.
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml              <- Project configuration file with package metadata.
‚îÇ
‚îú‚îÄ‚îÄ references                  <- Data dictionaries, manuals, and other explanatory materials.
‚îÇ
‚îú‚îÄ‚îÄ reports                     <- Generated analysis as HTML, PDF, LaTeX, etc.
‚îÇ   ‚îî‚îÄ‚îÄ figures                 <- Generated graphics and figures to be used in reporting.
‚îÇ
‚îú‚îÄ‚îÄ environment.yml             <- The environment file for reproducing the analysis environment.
‚îÇ
‚îú‚îÄ‚îÄ setup.cfg                   <- Configuration file for flake8.
‚îÇ
‚îî‚îÄ‚îÄ belly_rubb                  <- Source code for use in this project.
    ‚îÇ
    ‚îú‚îÄ‚îÄ __init__.py             <- Makes belly_rubb a Python module.
    ‚îÇ
    ‚îú‚îÄ‚îÄ config.py               <- Store useful variables and configuration.
    ‚îÇ
    ‚îú‚îÄ‚îÄ dataset.py              <- Scripts to download or generate data.
    ‚îÇ
    ‚îú‚îÄ‚îÄ features.py             <- Code to create features for modeling.
    ‚îÇ
    ‚îú‚îÄ‚îÄ modeling                
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py 
    ‚îÇ   ‚îú‚îÄ‚îÄ predict.py          <- Code to run model inference with trained models          
    ‚îÇ   ‚îî‚îÄ‚îÄ train.py            <- Code to train models
    ‚îÇ
    ‚îî‚îÄ‚îÄ plots.py                <- Code to create visualizations
```
---

## ‚öôÔ∏è Features & Tools

| Component              | Tool / Library                      |
|------------------------|-------------------------------------|
| Data Source            | Square (CSV/API)                    |
| Language               | Python                              |
| Data Storage           | SQLite                              |
| Data Pipeline          |                                     |
| EDA & Visualization    | pandas, matplotlib, seaborn         |
| Machine Learning       | scikit-learn                        |
| Deployment             |                                     |
| Version Control        | Git + GitHub                        |

---

## üìà Key Insights

*Note: Insights will be shared after model evaluation is complete.*

---

## ‚úÖ Project Development Checklist
- ‚úÖ Determine data mining goals.
- ‚úÖ Establish OAuth flow and connection to Square API.
- ‚òê Collect and clean data.
- ‚òê Perform exploratory data analysis (EDA) to gain insights and assess the business problem and context.
- ‚òê Transform data and engineer features to prepare for modeling.
- ‚òê Develop a model to address project's objectives.
- ‚òê Evaluate model performance.
- ‚òê Deploy model.

---

## üöÄ How to Run

1. Clone the repository:
    ```bash
    git clone https://github.com/ajamkotc/belly_rubb
    cd belly_rubb
    ```
2. Set up the Python virtual environment:
    ```bash
    conda env create -f environment.yml
    conda activate belly_rubb
    ```
3. Set up the `.env` file:
    ```bash
    SQUARE_APPLICATION_ID=your_square_application_id
    SQUARE_APPLICATION_SECRET=your_square_application_secret
    REDIRECT_URI=http://localhost:5000/callback
    ```
    - `SQUARE_APPLICATION_ID` and `SQUARE_APPLICATION_SECRET` can be obtained from your [Square Developer Dashboard](https://developer.squareup.com/docs/devtools/developer-dashboard).
    - `REDIRECT_URI` should match the redirect URL configured in your Square application settings.
    - For local development use `http://localhost:5000/callback`.
    - NEVER commit `.env` files to version control. Use `.gitignore` to exclude them.
3. Run the Pipeline
   ```bash
    # Run data processing scripts
    python src/data/dataset.py

    # Train the model
    python src/models/train_model.py
    ```
4. Launch the Dashboard

### ‚ö†Ô∏è Access Disclaimer

> This project demonstrates how to authenticate with the Square API and store access tokens securely using OAuth 2.0.
>
> You must use your own Square application credentials to run this app. Access to restaurant data requires permission from the account owner and valid API credentials.
>
> **Do not share or commit any real Square secrets or tokens.**