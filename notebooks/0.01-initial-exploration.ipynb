{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "import numpy as np\n",
    "\n",
    "# Time series analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from belly_rubb.config import REPORTS_DIR\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of DataFrames from the orders CSV files\n",
    "orders_dir = '../data/raw/orders'\n",
    "csv_files = [f for f in os.listdir(orders_dir) if f.endswith('.csv')]\n",
    "\n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(orders_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine dataframes into one\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rows: {df.shape[0]}\\nColumns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "df['Fulfillment Date'] = pd.to_datetime(df['Fulfillment Date'], format='%m/%d/%Y, %I:%M %p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Data Quality Checks\n",
    "- [x] Investigate missing values\n",
    "- [x] Identify static columns\n",
    "- [x] Check for duplicates\n",
    "- [x] Validate data types\n",
    "- [x] Spot outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "##### Missing values and static columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify empty or static columns\n",
    "\n",
    "for col in df.columns:\n",
    "    unique_values = set(df[col].dropna().unique())\n",
    "    if len(unique_values) == 0:\n",
    "        print(f\"Column '{col}' is empty.\")\n",
    "    elif len(unique_values) == 1:\n",
    "        print(f\"Column '{col}' has a single unique value: {unique_values.pop()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List distinct Recipient Country values\n",
    "\n",
    "df['Recipient Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_country = df[df['Recipient Country'] == 'ZZ']\n",
    "zz_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zz_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View missing value percentages\n",
    "\n",
    "df.isna().sum().div(len(df))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "* `Currency`, `Fulfillment Location`, and `Recipient Region` have a single unique value.\n",
    "* `Order Shipping Price`, `Order Refunded Amount`, and `Item SKU` are empty.\n",
    "* `Recipient Country` has 370 rows with the value `ZZ`.\n",
    "* Geographic details such as `Recipient Address` and `Recipient Postal Code` are missing greater than **87%** of their data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View rows with all null values\n",
    "\n",
    "df[df.isna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "duplicates = df.duplicated()\n",
    "df[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate 'Armen 59-07' rows\n",
    "\n",
    "df[(df['Order'] == 'Armen 59-07') & (df['Order Date'] == '2024/08/31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate Troy Issac rows\n",
    "\n",
    "df[(df['Order'] == 'Troy Issac') & (df['Order Date'] == '2024/12/19')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Each order is split into multiple rows, one for each menu item. Menu items are not grouped together however. For example, one order can have multiple rows with `CRINKLE FRIES` as the `Item name`. This implies that if items are part of separate combos or groupings, they are listed separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iqr(df: pd.DataFrame, col: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate the Interquartile Range (IQR) for a given column.\n",
    "    \n",
    "    Args:\n",
    "        col (str): The name of the column to calculate IQR for.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing the lower and upper bounds for outliers.\n",
    "    \"\"\"\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    return lower_bound, upper_bound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "##### Order Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers in Order Total\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.histplot(data=df, x='Order Total', color='skyblue')\n",
    "\n",
    "plt.title('Distribution of Order Total', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Order Total ($)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "lower_bound, upper_bound = calculate_iqr(df=df, col='Order Total')\n",
    "plt.axvline(x=df['Order Total'].mean(), color='red', linestyle='--', label='Mean')\n",
    "plt.axvline(x=df['Order Total'].median(), color='green', linestyle='--', label='Median')\n",
    "plt.axvline(x=lower_bound, color='orange', linestyle='-.', label='Lower Bound') if lower_bound > 0 else None\n",
    "plt.axvline(x=upper_bound, color='orange', linestyle='-.', label='Upper Bound')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print outlier information\n",
    "\n",
    "num_order_total_outliers = len(df[df['Order Total'] > upper_bound])\n",
    "print(f\"Number of outliers in 'Order Total': {num_order_total_outliers}\")\n",
    "print(f\"Percentage of total dataset: {num_order_total_outliers / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Order Total outliers\n",
    "\n",
    "order_total_outliers = df[df['Order Total'] > upper_bound].sort_values(by='Order Total', ascending=False)\n",
    "order_total_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "It appears that outliers in `Order Total` are simply large orders. At a cursory investigation there does not seem to be data entry mistakes or suspicious activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "##### Item Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers in Item Price\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.histplot(data=df, x='Item Price', color='skyblue')\n",
    "\n",
    "plt.title('Distribution of Item Price', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Item Price ($)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "lower_bound, upper_bound = calculate_iqr(df=df, col='Item Price')\n",
    "\n",
    "plt.axvline(x=df['Item Price'].mean(), color='red', linestyle='--', label='Mean')\n",
    "plt.axvline(x=df['Item Price'].median(), color='green', linestyle='--', label='Median')\n",
    "plt.axvline(x=lower_bound, color='orange', linestyle='-.', label='Lower Bound') if lower_bound > 0 else None\n",
    "plt.axvline(x=upper_bound, color='orange', linestyle='-.', label='Upper Bound')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Item Price outlier information\n",
    "\n",
    "num_item_price_outliers = len(df[df['Item Price'] > upper_bound])\n",
    "print(f\"Number of outliers in 'Item Price': {num_item_price_outliers}\")\n",
    "print(f\"Percentage of total dataset: {num_item_price_outliers / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Item Price outliers\n",
    "\n",
    "item_price_outliers = df[df['Item Price'] > upper_bound].sort_values(by='Item Price', ascending=False)\n",
    "item_price_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Item Price outlier Items\n",
    "\n",
    "item_price_outliers['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View outlier row with no item price\n",
    "\n",
    "item_price_outliers[item_price_outliers['Item Name'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "* Outliers in `Item Price` are catering packages, platters, bundles, and more expensive combos.\n",
    "* The outlier with no `Item Price` information appears to be a custom order lacking much information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "##### Item Options Total Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers in Item Options Total Price\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.histplot(data=df, x='Item Options Total Price', color='skyblue')\n",
    "\n",
    "plt.title('Distribution of Item Options Total Price', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Item Options Total Price ($)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "lower_bound, upper_bound = calculate_iqr(df=df, col='Item Options Total Price')\n",
    "\n",
    "plt.axvline(x=df['Item Options Total Price'].mean(), color='red', linestyle='--', label='Mean')\n",
    "plt.axvline(x=df['Item Options Total Price'].median(), color='green', linestyle='--', label='Median')\n",
    "plt.axvline(x=lower_bound, color='orange', linestyle='-.', label='Lower Bound') if lower_bound > 0 else None\n",
    "plt.axvline(x=upper_bound, color='orange', linestyle='-.', label='Upper Bound')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_options_total_price_outliers = df[df['Item Options Total Price'] > upper_bound].sort_values(by='Item Options Total Price', ascending=False)\n",
    "item_options_total_price_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of rows shared by all price outliers\n",
    "\n",
    "merged_df = pd.merge(left=item_price_outliers, right=item_options_total_price_outliers, left_index=True, right_index=True, how='inner', suffixes=('_item_price', '_item_options_total_price'))\n",
    "merged_df = pd.merge(left=merged_df, right=order_total_outliers, left_index=True, right_index=True, how='inner', suffixes=('', '_order_total'))\n",
    "\n",
    "print(f\"Number of merged outliers: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Rows which have a high `Item Price` also have a high `Item Options Total Price` and `Order Total`, signaling a relationship between these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify results with correlation heatmap\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.title('Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, center=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Business Logic Validation\n",
    "\n",
    "- [x] Investigate tax calculation\n",
    "- [x] Confirm total calculated correctly from subtotal\n",
    "- [x] Check for canceled/voided/refunded orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "##### Total Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect rows where Order Subtotal and Order Tax Total don't add up to Order Total\n",
    "\n",
    "tax_rate_valid = np.isclose((df['Order Subtotal'] + df['Order Tax Total']), df['Order Total'])\n",
    "df[~tax_rate_valid].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "It is not apparently cleaer why `Order Tax Total` and `Order Subtotal` do not add up to `Order Total` in all rows. Possible reasons could include added fees or tips, whose information is missing in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "#### Tax Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate effective tax rates\n",
    "\n",
    "tax_rate_valid_df = df[tax_rate_valid]\n",
    "(tax_rate_valid_df['Order Tax Total']/tax_rate_valid_df['Order Subtotal']).round(decimals=2).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each tax rate\n",
    "\n",
    "df['Tax Rate'] = (df['Order Tax Total']/df['Order Subtotal']).round(decimals=2)\n",
    "df.groupby(by='Tax Rate').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order with no tax calculated\n",
    "\n",
    "df[df['Tax Rate'] == 0.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Tax Rate'] == 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "The statewide tax rate in California is **7.25%**. In Los Angeles, the combined sales tax rate (state and local) is **9.50%**. While a majority of the orders are between 9-10%, there are a small amount with a much lower tax rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "#### Canceled/Voided/Refunded orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fulfillment Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View cancelled orders\n",
    "\n",
    "df[df['Fulfillment Status'] == 'Canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pseudo order id to be able to group orders\n",
    "\n",
    "df['pseudo_order_id'] = df['Order Name'].str.split(' ').str[0] + '_' + df['Order Date'].astype(str)\n",
    "df['pseudo_order_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of canceled orders\n",
    "\n",
    "cancelled_orders = df[df['Fulfillment Status'] == 'Canceled']\n",
    "num_canceled_orders = cancelled_orders['pseudo_order_id'].nunique()\n",
    "\n",
    "print(f\"Number of canceled orders: {num_canceled_orders}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View New orders\n",
    "\n",
    "df[df['Fulfillment Status'] == 'New']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View orders with no fulfillment status\n",
    "\n",
    "null_fulfillment_status = df[df['Fulfillment Status'].isnull()]\n",
    "null_fulfillment_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_fulfillment_status.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate Order Name for orders with no fulfillment status\n",
    "\n",
    "null_fulfillment_status['Order Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count fulfillment types including null values\n",
    "\n",
    "df['Fulfillment Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Channels of orders with no fulfillment status\n",
    "\n",
    "null_fulfillment_status['Channels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List refunded orders\n",
    "\n",
    "df[df['Order Refunded Amount'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "* There were a total of **6** cancelled orders.\n",
    "* **2** orders were listed as **New**. These were probably in progress at the time of capturing the data.\n",
    "* **1073** rows have no `Fulfillment Status` listed.\n",
    "    * These orders have primarily numeric `Order Name`.\n",
    "    * They are also missing `Fulfillment Type`.\n",
    "    * The single `Channel` for these rows is `BELLY RUBB - BBQ Ribs to Go & Catering`\n",
    "* There are no refunded orders. This probably means that `Order Refunded Amount` does not apply when `Fulfillment Status` is `Canceled`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "### Customer-Level Insights\n",
    "\n",
    "- [x] Count unique customers\n",
    "- [x] Identify repeat vs. new customers\n",
    "- [x] Explore order frequency (days between orders) for repeat customers\n",
    "- [x] Check for missing/anonymous customer records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "#### Unique Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of records where Order Name is the same as Recipient Name\n",
    "\n",
    "print(f\"Percentage of records where Order Name is the same as Recipient Name: {np.round(len(df[df['Order Name'] == df['Recipient Name']]) / len(df) * 100, decimals=2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate records where Order Name is not the same as Recipient Name\n",
    "\n",
    "order_recipient_name_neq = df[~(df['Order Name'] == df['Recipient Name'])]\n",
    "order_recipient_name_neq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of recipient names\n",
    "\n",
    "order_recipient_name_neq['Recipient Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of order names\n",
    "\n",
    "order_recipient_name_neq['Order Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_recipient_name_neq['Channels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique recipients\n",
    "\n",
    "print(f\"Number of unique customers: {len(df['Recipient Name'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "* **822** unique customers have ordered from the restaurant.\n",
    "* In **73%** of records `Order Name` and `Recipient Name` are equal.\n",
    "    * This allows us to rely on `Recipient Name` to later investigate repeat customers.\n",
    "* The rest all have missing `Recipient Name` and majority cryptic `Order Name`.\n",
    "    * These records are also those with null `Fulfillment Status`.\n",
    "    * Since they all have a single value for `Channel`, namely `BELLY RUBB - BBQ Ribs To Go & Catering`, it can be assumed that these are manually entered entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "#### Repeat Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of repeat orders\n",
    "\n",
    "order_names = df.groupby(by='pseudo_order_id')['Recipient Name'].unique().str[0]\n",
    "repeat_counts = order_names.value_counts()\n",
    "repeat_customers = repeat_counts[repeat_counts > 1]\n",
    "\n",
    "print(f\"Number of repeat customers: {len(repeat_customers)}\")\n",
    "print(f\"Percentage of customers who are repeat customers: {(len(repeat_customers) / repeat_counts.shape[0]) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Repeat Customer Frequency Distribution\n",
    "\n",
    "recipient_freq = repeat_customers.value_counts(normalize=True).sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.title('Repeat Customer Frequency Distribution', fontsize=16, fontweight='bold')\n",
    "plt.bar(recipient_freq.index, recipient_freq.values)\n",
    "\n",
    "plt.xlabel('Number of Repeat Orders', fontsize=14)\n",
    "plt.ylabel('Percentage of Customers', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Cumulative Distribution of Repeat Customers\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.hist(repeat_customers, cumulative=True, density=True, bins=range(2, repeat_customers.max() + 2), edgecolor='black', color='skyblue', alpha=0.7)\n",
    "\n",
    "plt.title('Cumulative Distribution of Repeat Customers', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Number of Repeat Orders', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "* Approximately **10.87%** of customers are repeat customers, constituting customer who have ordered at least twice.\n",
    "* The distribution of repeat orders is heavily **right-skewed**, as expected.\n",
    "    * About **60%** of repeat customers have ordered **2** times.\n",
    "    * About **80%** of repeat customers have ordered **4 or less** times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "#### Order frequency for repeat customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_days_difference(date1: datetime, date2: datetime) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the number of days between two dates.\n",
    "    \n",
    "    Args:\n",
    "        date1 (datetime): The first date.\n",
    "        date2 (datetime): The second date.\n",
    "        \n",
    "    Returns:\n",
    "        int: The number of days between the two dates.\n",
    "    \"\"\"\n",
    "    return (date2 - date1).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create row to signify if customer is a repeat customer\n",
    "\n",
    "df['repeat_customer'] = df['Recipient Name'].isin(repeat_customers.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for repeat customers\n",
    "\n",
    "repeat_customers_df = df[(df['repeat_customer']) & (df['Fulfillment Status'] == 'Completed')]\n",
    "repeat_customers_df = repeat_customers_df.sort_values(by=['Recipient Name', 'Order Date'])\n",
    "repeat_customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with one row per order for repeat customers\n",
    "\n",
    "order_df = repeat_customers_df.groupby(by=['pseudo_order_id']).agg({\n",
    "    'Order Date': 'first',\n",
    "    'Recipient Name': 'first'\n",
    "}).sort_values(by=['Recipient Name', 'Order Date']).reset_index()\n",
    "\n",
    "order_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for previous order date\n",
    "\n",
    "order_df['previous_order_date'] = order_df.groupby(by='Recipient Name')['Order Date'].shift(1)\n",
    "order_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate days since last order per customer\n",
    "\n",
    "order_df['days_since_last_order'] = order_df['Order Date'].sub(order_df['previous_order_date']).dt.days\n",
    "avg_days_since_last_order = order_df.groupby(by='Recipient Name')['days_since_last_order'].mean().sort_values()\n",
    "avg_days_since_last_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of average days between orders\n",
    "\n",
    "avg_days_counts = avg_days_since_last_order.value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Distribution of Average Days Since Last Order\", fontsize=16, fontweight='bold')\n",
    "plt.hist(avg_days_since_last_order, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Average Days Since Last Order', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "mean_avg_days = avg_days_since_last_order.mean()\n",
    "median_avg_days = avg_days_since_last_order.median()\n",
    "\n",
    "plt.axvline(mean_avg_days, color='red', linestyle='dashed', linewidth=1, label='Mean')\n",
    "plt.text(mean_avg_days*1.1, plt.ylim()[1]*0.8, np.round(mean_avg_days, 1), color='red', ha='center')\n",
    "plt.axvline(median_avg_days, color='blue', linestyle='dashed', linewidth=1, label='Median')\n",
    "plt.text(median_avg_days*1.15, plt.ylim()[1]*0.8, np.round(median_avg_days, 1), color='blue', ha='center')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "* The *average number of days* between repeat orders is **54.2 days**.\n",
    "* The *median number of days* between repeat orders is **35 days**.\n",
    "* Distribution of average days between orders is also heavily **right-skewed**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "#### Missing Customer Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect customer record columns\n",
    "\n",
    "customer_record_cols = ['Recipient Name', 'Recipient Email', 'Recipient Phone', 'Recipient Address', 'Recipient Postal Code', 'Recipient City', 'Recipient Region', 'Recipient Country']\n",
    "\n",
    "df[customer_record_cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of records missing for each customer record column\n",
    "\n",
    "np.round(df[customer_record_cols].isna().sum() / len(df) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect customer records with missing Recipient Name\n",
    "\n",
    "df[df['Recipient Name'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "* **87%** of recipient address information is missing.\n",
    "* **50%** of recipient emails are missing.\n",
    "* **26%** of recipient names are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "### Time-Based Patterns\n",
    "\n",
    "- [x] Confirm dataset start and end dates\n",
    "- [x] Explore order volume by day of week\n",
    "- [x] Explore order volume by hour of day\n",
    "- [x] Look for seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "#### Confirm dataset start and end dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify order date is datetime\n",
    "\n",
    "print(f\"Order Date is datetime: {is_datetime(df['Order Date'])}\")\n",
    "print(f\"Fulfillment Date is datetime: {is_datetime(df['Fulfillment Date'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series DataFrame with each row corresponding to one order and Order Date as index\n",
    "\n",
    "time_series_df = df.groupby('pseudo_order_id').agg({\n",
    "    'Order Date': 'first',\n",
    "    'Order Total': 'first'\n",
    "}).sort_values(by='Order Date').reset_index().set_index('Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series DataFrame with each row corresponding to one order and Fulfillment Date as index\n",
    "\n",
    "time_series_fulfillment_df = df.groupby('pseudo_order_id').agg({\n",
    "    'Fulfillment Date': 'first',\n",
    "    'Order Total': 'first'\n",
    "}).sort_values(by='Fulfillment Date').reset_index().set_index('Fulfillment Date')\n",
    "\n",
    "time_series_fulfillment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect time series DataFrame\n",
    "\n",
    "time_series_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print earliest and latest order date to confirm range\n",
    "\n",
    "print(f\"Earliest order date: {time_series_df.index.min()}\")\n",
    "print(f\"Latest order date: {time_series_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print earliest and latest order date to confirm range\n",
    "\n",
    "print(f\"Earliest order date: {time_series_fulfillment_df.index.min()}\")\n",
    "print(f\"Latest order date: {time_series_fulfillment_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "* `Fulfillment Date` is missing for orders before **12/5/2023**.\n",
    "* `Order date` is available for all orders and spans the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "#### Explore order volume by day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample frequency to daily and add day of week column\n",
    "\n",
    "day_of_week_orders = time_series_df.resample('D').size().reset_index(name='orders_count')\n",
    "day_of_week_orders['day_of_week'] = day_of_week_orders['Order Date'].dt.day_name()\n",
    "day_of_week_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average number of orders per day of week\n",
    "\n",
    "week_day_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "\n",
    "day_of_week_means = day_of_week_orders.groupby(by='day_of_week')['orders_count'].mean().reindex(week_day_order)\n",
    "day_of_week_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median number of orders per day of week\n",
    "\n",
    "day_of_week_medians = day_of_week_orders.groupby(by='day_of_week')['orders_count'].median().reindex(week_day_order)\n",
    "day_of_week_medians.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sales by day of the week\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "fig.suptitle('Orders per Day of Week', fontsize=16, fontweight='bold')\n",
    "\n",
    "day_of_week_means.plot(ax=ax[0])\n",
    "ax[0].set_title('Mean Orders', fontsize=14, fontweight='bold')\n",
    "ax[0].set_xlabel('', fontsize=12)\n",
    "\n",
    "day_of_week_medians.plot(ax=ax[1])\n",
    "ax[1].set_title('Median Orders', fontsize=14, fontweight='bold')\n",
    "ax[1].set_xlabel('', fontsize=12)\n",
    "\n",
    "fig.supylabel('Number of Orders', fontsize=12)\n",
    "fig.supxlabel('Day of Week', fontsize=12)\n",
    "\n",
    "ax[0].grid(visible=True, axis='both', linestyle='--', alpha=0.7)\n",
    "ax[1].grid(visible=True, axis='both', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "* Trends between *mean* and *median* orders per day of week are similar.\n",
    "* **Fridays** have the highest number of orders, followed by **Tuesdays**.\n",
    "* Some orders have been taken on Sundays and Mondays, but this is irrelevant since they are outside business hours.\n",
    "* **Saturdays**, **Wednesdays**, and **Thursdays** share similar *mean* and *median* order quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "#### Explore order volume by hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_fulfillment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to hourly frequency\n",
    "\n",
    "hour_of_day_orders = time_series_fulfillment_df.resample('h').size().reset_index(name='orders_count')\n",
    "\n",
    "hour_of_day_orders['hour_of_day'] = hour_of_day_orders['Fulfillment Date'].dt.hour\n",
    "hour_of_day_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and median orders per hour of day\n",
    "\n",
    "hour_of_day_means = hour_of_day_orders.groupby(by='hour_of_day')['orders_count'].mean()\n",
    "hour_of_day_totals = hour_of_day_orders.groupby('hour_of_day')['orders_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sales by hour\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "fig.suptitle('Orders per Hour of Day', fontsize=16, fontweight='bold')\n",
    "\n",
    "hour_of_day_means.plot(ax=ax[0])\n",
    "ax[0].set_title('Mean Orders', fontsize=14, fontweight='bold')\n",
    "ax[0].set_ylabel('Mean Orders', fontsize=12)\n",
    "ax[0].set_xlabel('')\n",
    "\n",
    "hour_of_day_totals.plot(ax=ax[1])\n",
    "ax[1].set_title('Total Orders', fontsize=14, fontweight='bold')\n",
    "ax[1].set_ylabel('Total Orders', fontsize=12)\n",
    "ax[1].set_xlabel('')\n",
    "\n",
    "fig.supxlabel('Hour of Day', fontsize=12)\n",
    "\n",
    "ax[0].grid(visible=True, axis='both', linestyle='--', alpha=0.7)\n",
    "ax[1].grid(visible=True, axis='both', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "* `Order Date` does not store timestamp data, therefore `Fulfillment Date` was used to get hourly order data.\n",
    "* Peak order time is around **7pm**\n",
    "* Orders **decrease** closer to closing time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "#### Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for weekly seasonality\n",
    "\n",
    "result = seasonal_decompose(day_of_week_orders['orders_count'], period=7)\n",
    "\n",
    "fig = result.plot()\n",
    "fig.set_size_inches(12, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "* Since there are only **22** months worth of data, we cannot check for *monthly seasonality*.\n",
    "* Seasonal decomposition confirms that there is a **weekly** seasonal cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "### Menu and Product-Level Insights\n",
    "\n",
    "- [x] Count unique items sold\n",
    "- [x] Check for item categories (main, side, etc.)\n",
    "- [x] Rank top-selling items (by quantity, revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "#### Unique Items Sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect quantity of unique item names\n",
    "\n",
    "print(f\"Number of unique item names: {len(df['Item Name'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique number of item and item variation combinations\n",
    "\n",
    "name_vars_counts = df.groupby(by='Item Name')['Item Variation'].nunique().sort_values(ascending=False).reset_index(name='count')\n",
    "print(f\"Number of unique item and variation combinations: {np.sum(name_vars_counts['count'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "* Belly Rubb offers **104** unique items based on `Item Name`.\n",
    "* **135** unique combinations of items and their variations have been sold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "#### Item Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See list of possible item variations\n",
    "\n",
    "df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique sides offered: {len(df[df['Item Variation'] == 'Side']['Item Name'].unique())}\")\n",
    "print(f\"Unique sides: {df[df['Item Variation'] == 'Side']['Item Name'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Truffle Salt']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Rosemary Pepper']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == '6 pcs']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See number of orders per method of spelling Mac & Cheese\n",
    "\n",
    "mac_and_cheese_variations = ['ARTISAN MAC AND CHEESE', 'MAC&CHEESE', 'Artisan Mac and Cheese']\n",
    "\n",
    "variant_counts = {}\n",
    "\n",
    "for variant in mac_and_cheese_variations:\n",
    "    variant_counts[variant] = len(df[df['Item Name'] == variant])\n",
    "\n",
    "variant_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Name'] == 'Artisan Mac and Cheese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See variations of Mac & Cheese ordered\n",
    "\n",
    "df[df['Item Name'].isin(mac_and_cheese_variations)]['Item Variation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See variations of Pineapple Slaw ordered\n",
    "\n",
    "df[df['Item Name'] == 'PINEAPPLE SLAW']['Item Variation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Full Rack'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Full Rack']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Full'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Full']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_items = df[df['Item Variation'] == 'Regular']\n",
    "regular_items['Item Name'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_items['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Name'] == 'BEEF BACK RIBS (FULL RACK)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Name'] == 'Beef Back Ribs (Full Rack)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142",
   "metadata": {},
   "source": [
    "* `Item Name` and `Item Variations` have duplicate entries with variations in spelling.\n",
    "    * Mac & Cheese has **three** different spellings: `ARTISAN MAC AND CHEESE`, `MAC&CHEESE`, `Artisan Mac and Cheese`\n",
    "    * A full rack of beef back ribs has **two** different spellings: `Beef Back Ribs (Full Rack)`, and `BEEF BACK RIBS (FULL RACK)`\n",
    "        * Both orders are from `DOORDASH` so that can't explain the difference.\n",
    "    * There are **four** different spellings for Baby back pork ribs: `GLAZED BABY BACK PORK RIBS`, `BABY BACK PORK RIBS`, `GET YOUR BABY BACK!`, and `\"Get your baby back\" Pork Ribs`.\n",
    "* Side items, such as the Mac & Cheese and slaw can have `Item Variation` set to `Full`, `Side`, or `8oz`.\n",
    "* `Item Variation` `Regular` seems to imply to not apply any variations.\n",
    "    * `Full Rack` relates to orders of pork ribs.\n",
    "    * `Side`, `Full`, and `8oz` relate to orders of sides.\n",
    "    * Values with `pcs` relate to items that come in multiples such as Chicken Wings and Mozzarella Sticks\n",
    "    * Seasoning variations such as `Rosemary Pepper` and `Truffle Salt` relate to orders of fries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143",
   "metadata": {},
   "source": [
    "#### Top-selling Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144",
   "metadata": {},
   "source": [
    "##### Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect quantity of items and their variations ordered\n",
    "\n",
    "item_variation_counts = df.groupby(by=['Item Name', 'Item Variation']).size().sort_values(ascending=False).reset_index(name='count')\n",
    "\n",
    "item_variation_counts.to_csv(REPORTS_DIR / 'item_variation_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect quantity of items ordered\n",
    "\n",
    "item_counts = df.groupby(by='Item Name').size().sort_values(ascending=False).reset_index(name='count')\n",
    "\n",
    "item_counts.to_csv(REPORTS_DIR / 'item_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See top 10 performing items\n",
    "\n",
    "item_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See top 10 performing items and their variations\n",
    "\n",
    "item_variation_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See bottom 10 performing items\n",
    "\n",
    "item_counts.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See bottom 10 performing items and their variations\n",
    "\n",
    "item_variation_counts.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151",
   "metadata": {},
   "source": [
    "##### Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Quantity'] > 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List top 10 performing items based on revenue\n",
    "\n",
    "item_revenues = df.groupby(by='Item Name')['Item Total Price'].sum().sort_values(ascending=False).reset_index(name='total_revenue')\n",
    "item_revenues.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List top 10 performing items and their variations based on revenue\n",
    "\n",
    "item_combination_revenues = df.groupby(by=['Item Name', 'Item Variation'])['Item Total Price'].sum().sort_values(ascending=False).reset_index(name='total_revenue')\n",
    "item_combination_revenues.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List worst 10 performing items based on revenue\n",
    "\n",
    "item_revenues.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List items with zero revenue\n",
    "\n",
    "item_revenues[item_revenues['total_revenue'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157",
   "metadata": {},
   "source": [
    "Condiments provide **zero** revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List worst 10 performing items and their variations based on revenue\n",
    "\n",
    "item_combination_revenues[item_combination_revenues['total_revenue'] > 0].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159",
   "metadata": {},
   "source": [
    "* Items ranked by revenue:\n",
    "    1. `GLAZED BABY BACK PORK RIBS`: **$16,092.10**\n",
    "    2. `BEEF BACK RIBS (Full Rack)`: **$11,299.39**\n",
    "    3. `STEAK SANDWICH COMBO`: **$6,297.93**\n",
    "* Items and variations ranked by revenue:\n",
    "    1. Full Rack of Glazed Baby Back Pork Ribs: **$12,391.97**\n",
    "    2. Regular order of Beef Back Ribs (Full Rack): **$11,299.39**\n",
    "    3. Regular order of Steak Sandwich Combo: **$6297.93**\n",
    "* Items ranked lowest by revenue:\n",
    "    1. `Pickled Jalapenos (8oz)`: **$1.64**\n",
    "    2. `BLUE CHEESE SAUCE`: **$2.05**\n",
    "    3. `BBQ dipping sauce`: **$2.55**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160",
   "metadata": {},
   "source": [
    "### Revenue & Payments\n",
    "\n",
    "- [x] Total Sales, average order value, median order value.\n",
    "- [] Check for chargebacks/refunds and their impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {},
   "source": [
    "#### Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with order-level information\n",
    "\n",
    "orders_df = df.groupby(by='pseudo_order_id').agg({\n",
    "    'Order Total': 'first',\n",
    "    'Order Refunded Amount': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total sales\n",
    "\n",
    "print(f\"Total Sales: {orders_df['Order Total'].sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for Order Total\n",
    "\n",
    "orders_df['Order Total'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166",
   "metadata": {},
   "source": [
    "* There were a total of **1,432** orders since opening.\n",
    "* Total Sales = **$90,341.63**\n",
    "* Average Sale Amount = **$63.08**\n",
    "* Median Sale Amount = **$50.44**\n",
    "* Maximum Sale Amount = **$1,158.75**\n",
    "* Minimum Sale Amount = **$1.00**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167",
   "metadata": {},
   "source": [
    "#### Refunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for order refunded amount\n",
    "\n",
    "orders_df['Order Refunded Amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169",
   "metadata": {},
   "source": [
    "* All values in `Order Refunded Amount` are **NaN**.\n",
    "* This either means that there were no refunded orders, or that this information is not tracked in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170",
   "metadata": {},
   "source": [
    "### Conclusions and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171",
   "metadata": {},
   "source": [
    "***Data Quality Checks***\n",
    "\n",
    "- Columns `Currency`, `Order Shipping Price`, `Order Refunded Amount`, `Fulfillment Location`, `Recipient Region`, and `Item SKU` carry no valuabe information and can be dropped from the dataset.\n",
    "- Geographic details such as `Address`, `Postal Code`, `City`, `Region` are missing greater than **87%** of entries.\n",
    "\n",
    "**Business Logic Validation**\n",
    "* Outliers in `Item Price` are catering packages, platters, bundles, and combos.\n",
    "* There are **no** refunded orders.\n",
    "    * There were **6** cancelled orders.\n",
    "* **1,073** rows are missing Fulfillment data.\n",
    "\n",
    "**Customer-Level Insights**\n",
    "* **822** unique customers.\n",
    "* **11%** of customers are repeat customers (have ordered more than once).\n",
    "    * **60%** of repeat customers order at most **2** times.\n",
    "    * The *average number of days* between repeat orers is **54.2 days**.\n",
    "    * The *median number of days* between repeat orders if **35 days**.\n",
    "\n",
    "**Time-Based Patterns**\n",
    "* **Fridays** have the highest number of orders.\n",
    "    * **Tuesdays** are the second most popular days.\n",
    "    * Other days of the week have similar *mean* and *median* order quantities.\n",
    "* Peak order time is around **7pm**.\n",
    "\n",
    "**Menu and Product-Level Insights**\n",
    "* **135** unique combinations of items and their variations have been sold.\n",
    "* Menu item names need to be standardized.\n",
    "* `Item Variation` applies to both main and side dishes.\n",
    "    * Can't be used as a *category* feature.\n",
    "* Baby Back Pork Ribs is the **most ordered** item and provides the **highest revenue**.\n",
    "* Some items have very low sales and need further exploration.\n",
    "\n",
    "**Revenue & Payments**\n",
    "* Total Sales: **$90,341.63**\n",
    "* Average Order Amount: **$63.08**\n",
    "* Median Order Amount: **$50.44**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belly_rubb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
