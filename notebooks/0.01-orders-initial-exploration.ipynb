{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "import numpy as np\n",
    "\n",
    "# Time series analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from belly_rubb.config import REPORTS_DIR, INTERIM_DATA_DIR, RAW_DATA_DIR\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of DataFrames from the orders CSV files\n",
    "orders_dir = '../data/raw/orders'\n",
    "csv_files = [f for f in os.listdir(orders_dir) if f.endswith('.csv')]\n",
    "\n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(orders_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine dataframes into one\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save aggregated orders data to csv\n",
    "\n",
    "df.to_csv(INTERIM_DATA_DIR / 'orders.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rows: {df.shape[0]}\\nColumns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "df['Fulfillment Date'] = pd.to_datetime(df['Fulfillment Date'], format='%m/%d/%Y, %I:%M %p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Data Quality Checks\n",
    "- [x] Investigate missing values\n",
    "- [x] Identify static columns\n",
    "- [x] Check for duplicates\n",
    "- [x] Validate data types\n",
    "- [x] Spot outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Missing values and static columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify empty or static columns\n",
    "\n",
    "for col in df.columns:\n",
    "    unique_values = set(df[col].dropna().unique())\n",
    "    if len(unique_values) == 0:\n",
    "        print(f\"Column '{col}' is empty.\")\n",
    "    elif len(unique_values) == 1:\n",
    "        print(f\"Column '{col}' has a single unique value: {unique_values.pop()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List distinct Recipient Country values\n",
    "\n",
    "df['Recipient Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_country = df[df['Recipient Country'] == 'ZZ']\n",
    "zz_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zz_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View missing value percentages\n",
    "\n",
    "df.isna().sum().div(len(df))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* `Currency`, `Fulfillment Location`, and `Recipient Region` have a single unique value.\n",
    "* `Order Shipping Price`, `Order Refunded Amount`, and `Item SKU` are empty.\n",
    "* `Recipient Country` has 370 rows with the value `ZZ`.\n",
    "* Geographic details such as `Recipient Address` and `Recipient Postal Code` are missing greater than **87%** of their data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View rows with all null values\n",
    "\n",
    "df[df.isna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "No row is missing **all** values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "duplicates = df.duplicated()\n",
    "df[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate 'Armen 59-07' rows\n",
    "\n",
    "df[(df['Order'] == 'Armen 59-07') & (df['Order Date'] == '2024/08/31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate Troy Issac rows\n",
    "\n",
    "df[(df['Order'] == 'Troy Issac') & (df['Order Date'] == '2024/12/19')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "* Each order is split into multiple rows, one for each menu item.\n",
    "* Menu items are not grouped together however. For example, one order can have multiple rows with `CRINKLE FRIES` as the `Item name`. \n",
    "* If items are part of separate combos or groupings, they are listed separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iqr(df: pd.DataFrame, col: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate the Interquartile Range (IQR) for a given column.\n",
    "    \n",
    "    Args:\n",
    "        col (str): The name of the column to calculate IQR for.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing the lower and upper bounds for outliers.\n",
    "    \"\"\"\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    return lower_bound, upper_bound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Order Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers in Order Total\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.histplot(data=df, x='Order Total', color='skyblue')\n",
    "\n",
    "plt.title('Distribution of Order Total', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Order Total ($)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "lower_bound, upper_bound = calculate_iqr(df=df, col='Order Total')\n",
    "plt.axvline(x=df['Order Total'].mean(), color='red', linestyle='--', label='Mean')\n",
    "plt.axvline(x=df['Order Total'].median(), color='green', linestyle='--', label='Median')\n",
    "plt.axvline(x=lower_bound, color='orange', linestyle='-.', label='Lower Bound') if lower_bound > 0 else None\n",
    "plt.axvline(x=upper_bound, color='orange', linestyle='-.', label='Upper Bound')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print outlier information\n",
    "\n",
    "num_order_total_outliers = len(df[df['Order Total'] > upper_bound])\n",
    "print(f\"Number of outliers in 'Order Total': {num_order_total_outliers}\")\n",
    "print(f\"Percentage of total dataset: {num_order_total_outliers / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Order Total outliers\n",
    "\n",
    "order_total_outliers = df[df['Order Total'] > upper_bound].sort_values(by='Order Total', ascending=False)\n",
    "order_total_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "* Outliers in `Order Total` are simply large orders.\n",
    "* There does not seem to be data entry mistakes or suspicious activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Item Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers in Item Price\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.histplot(data=df, x='Item Price', color='skyblue')\n",
    "\n",
    "plt.title('Distribution of Item Price', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Item Price ($)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "lower_bound, upper_bound = calculate_iqr(df=df, col='Item Price')\n",
    "\n",
    "plt.axvline(x=df['Item Price'].mean(), color='red', linestyle='--', label='Mean')\n",
    "plt.axvline(x=df['Item Price'].median(), color='green', linestyle='--', label='Median')\n",
    "plt.axvline(x=lower_bound, color='orange', linestyle='-.', label='Lower Bound') if lower_bound > 0 else None\n",
    "plt.axvline(x=upper_bound, color='orange', linestyle='-.', label='Upper Bound')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Item Price outlier information\n",
    "\n",
    "num_item_price_outliers = len(df[df['Item Price'] > upper_bound])\n",
    "print(f\"Number of outliers in 'Item Price': {num_item_price_outliers}\")\n",
    "print(f\"Percentage of total dataset: {num_item_price_outliers / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Item Price outliers\n",
    "\n",
    "item_price_outliers = df[df['Item Price'] > upper_bound].sort_values(by='Item Price', ascending=False)\n",
    "item_price_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Item Price outlier Items\n",
    "\n",
    "item_price_outliers['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View outlier row with no item price\n",
    "\n",
    "item_price_outliers[item_price_outliers['Item Name'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "* Outliers in `Item Price` are catering packages, platters, bundles, and more expensive combos.\n",
    "* The outlier with no `Item Price` information appears to be a custom order lacking much information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Item Options Total Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers in Item Options Total Price\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.histplot(data=df, x='Item Options Total Price', color='skyblue')\n",
    "\n",
    "plt.title('Distribution of Item Options Total Price', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Item Options Total Price ($)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "lower_bound, upper_bound = calculate_iqr(df=df, col='Item Options Total Price')\n",
    "\n",
    "plt.axvline(x=df['Item Options Total Price'].mean(), color='red', linestyle='--', label='Mean')\n",
    "plt.axvline(x=df['Item Options Total Price'].median(), color='green', linestyle='--', label='Median')\n",
    "plt.axvline(x=lower_bound, color='orange', linestyle='-.', label='Lower Bound') if lower_bound > 0 else None\n",
    "plt.axvline(x=upper_bound, color='orange', linestyle='-.', label='Upper Bound')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_options_total_price_outliers = df[df['Item Options Total Price'] > upper_bound].sort_values(by='Item Options Total Price', ascending=False)\n",
    "item_options_total_price_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of rows shared by all price outliers\n",
    "\n",
    "merged_df = pd.merge(left=item_price_outliers, right=item_options_total_price_outliers, left_index=True, right_index=True, how='inner', suffixes=('_item_price', '_item_options_total_price'))\n",
    "merged_df = pd.merge(left=merged_df, right=order_total_outliers, left_index=True, right_index=True, how='inner', suffixes=('', '_order_total'))\n",
    "\n",
    "print(f\"Number of merged outliers: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "Rows which have a high `Item Price` also have a high `Item Options Total Price` and `Order Total`, signaling a relationship between these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify results with correlation heatmap\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.title('Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, center=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# Business Logic Validation\n",
    "\n",
    "- [x] Investigate tax calculation\n",
    "- [x] Confirm total calculated correctly from subtotal\n",
    "- [x] Check for canceled/voided/refunded orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Total Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect rows where Order Subtotal and Order Tax Total don't add up to Order Total\n",
    "\n",
    "tax_rate_valid = np.isclose((df['Order Subtotal'] + df['Order Tax Total']), df['Order Total'])\n",
    "df[~tax_rate_valid].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "It is not apparently cleaer why `Order Tax Total` and `Order Subtotal` do not add up to `Order Total` in all rows. Possible reasons could include added fees or tips, whose information is missing in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## Tax Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate effective tax rates\n",
    "\n",
    "tax_rate_valid_df = df[tax_rate_valid]\n",
    "(tax_rate_valid_df['Order Tax Total']/tax_rate_valid_df['Order Subtotal']).round(decimals=2).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each tax rate\n",
    "\n",
    "df['Tax Rate'] = (df['Order Tax Total']/df['Order Subtotal']).round(decimals=2)\n",
    "df.groupby(by='Tax Rate').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order with no tax calculated\n",
    "\n",
    "df[df['Tax Rate'] == 0.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Tax Rate'] == 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "The statewide tax rate in California is **7.25%**. In Los Angeles, the combined sales tax rate (state and local) is **9.50%**. While a majority of the orders are between 9-10%, there are a small amount with a much lower tax rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Canceled/Voided/Refunded orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fulfillment Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View cancelled orders\n",
    "\n",
    "df[df['Fulfillment Status'] == 'Canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pseudo order id to be able to group orders\n",
    "\n",
    "df['pseudo_order_id'] = df['Order Name'].str.split(' ').str[0] + '_' + df['Order Date'].astype(str)\n",
    "df['pseudo_order_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of canceled orders\n",
    "\n",
    "cancelled_orders = df[df['Fulfillment Status'] == 'Canceled']\n",
    "num_canceled_orders = cancelled_orders['pseudo_order_id'].nunique()\n",
    "\n",
    "print(f\"Number of canceled orders: {num_canceled_orders}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View New orders\n",
    "\n",
    "df[df['Fulfillment Status'] == 'New']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View orders with no fulfillment status\n",
    "\n",
    "null_fulfillment_status = df[df['Fulfillment Status'].isnull()]\n",
    "null_fulfillment_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_fulfillment_status.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate Order Name for orders with no fulfillment status\n",
    "\n",
    "null_fulfillment_status['Order Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count fulfillment types including null values\n",
    "\n",
    "df['Fulfillment Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Channels of orders with no fulfillment status\n",
    "\n",
    "null_fulfillment_status['Channels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List refunded orders\n",
    "\n",
    "df[df['Order Refunded Amount'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* There were a total of **6** cancelled orders.\n",
    "* **2** orders were listed as **New**. These were probably in progress at the time of capturing the data.\n",
    "* **1073** rows have no `Fulfillment Status` listed.\n",
    "    * These orders have primarily numeric `Order Name`.\n",
    "    * They are also missing `Fulfillment Type`.\n",
    "    * The single `Channel` for these rows is `BELLY RUBB - BBQ Ribs to Go & Catering`\n",
    "* There are no refunded orders. This probably means that `Order Refunded Amount` does not apply when `Fulfillment Status` is `Canceled`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "# Customer-Level Insights\n",
    "\n",
    "- [x] Count unique customers\n",
    "- [x] Identify repeat vs. new customers\n",
    "- [x] Explore order frequency (days between orders) for repeat customers\n",
    "- [x] Check for missing/anonymous customer records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "## Unique Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of records where Order Name is the same as Recipient Name\n",
    "\n",
    "print(f\"Percentage of records where Order Name is the same as Recipient Name: {np.round(len(df[df['Order Name'] == df['Recipient Name']]) / len(df) * 100, decimals=2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate records where Order Name is not the same as Recipient Name\n",
    "\n",
    "order_recipient_name_neq = df[~(df['Order Name'] == df['Recipient Name'])]\n",
    "order_recipient_name_neq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of recipient names\n",
    "\n",
    "order_recipient_name_neq['Recipient Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of order names\n",
    "\n",
    "order_recipient_name_neq['Order Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_recipient_name_neq['Channels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique recipients\n",
    "\n",
    "print(f\"Number of unique customers: {len(df['Recipient Name'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* **822** unique customers have ordered from the restaurant.\n",
    "* In **73%** of records `Order Name` and `Recipient Name` are equal.\n",
    "    * This allows us to rely on `Recipient Name` to later investigate repeat customers.\n",
    "* The rest all have missing `Recipient Name` and majority cryptic `Order Name`.\n",
    "    * These records are also those with null `Fulfillment Status`.\n",
    "    * Since they all have a single value for `Channel`, namely `BELLY RUBB - BBQ Ribs To Go & Catering`, it can be assumed that these are manually entered entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "## Repeat Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of repeat orders\n",
    "\n",
    "order_names = df.groupby(by='pseudo_order_id')['Recipient Name'].unique().str[0]\n",
    "repeat_counts = order_names.value_counts()\n",
    "repeat_customers = repeat_counts[repeat_counts > 1]\n",
    "\n",
    "print(f\"Number of repeat customers: {len(repeat_customers)}\")\n",
    "print(f\"Percentage of customers who are repeat customers: {(len(repeat_customers) / repeat_counts.shape[0]) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Repeat Customer Frequency Distribution\n",
    "\n",
    "recipient_freq = repeat_customers.value_counts(normalize=True).sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.title('Repeat Customer Frequency Distribution', fontsize=16, fontweight='bold')\n",
    "plt.bar(recipient_freq.index, recipient_freq.values)\n",
    "\n",
    "plt.xlabel('Number of Repeat Orders', fontsize=14)\n",
    "plt.ylabel('Percentage of Customers', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Cumulative Distribution of Repeat Customers\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.hist(repeat_customers, cumulative=True, density=True, bins=range(2, repeat_customers.max() + 2), edgecolor='black', color='skyblue', alpha=0.7)\n",
    "\n",
    "plt.title('Cumulative Distribution of Repeat Customers', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Number of Repeat Orders', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* Approximately **10.87%** of customers are repeat customers, constituting customer who have ordered at least twice.\n",
    "* The distribution of repeat orders is heavily **right-skewed**, as expected.\n",
    "    * About **60%** of repeat customers have ordered **2** times.\n",
    "    * About **80%** of repeat customers have ordered **4 or less** times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "## Order frequency for repeat customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_days_difference(date1: datetime, date2: datetime) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the number of days between two dates.\n",
    "    \n",
    "    Args:\n",
    "        date1 (datetime): The first date.\n",
    "        date2 (datetime): The second date.\n",
    "        \n",
    "    Returns:\n",
    "        int: The number of days between the two dates.\n",
    "    \"\"\"\n",
    "    return (date2 - date1).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create row to signify if customer is a repeat customer\n",
    "\n",
    "df['repeat_customer'] = df['Recipient Name'].isin(repeat_customers.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for repeat customers\n",
    "\n",
    "repeat_customers_df = df[(df['repeat_customer']) & (df['Fulfillment Status'] == 'Completed')]\n",
    "repeat_customers_df = repeat_customers_df.sort_values(by=['Recipient Name', 'Order Date'])\n",
    "repeat_customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with one row per order for repeat customers\n",
    "\n",
    "order_df = repeat_customers_df.groupby(by=['pseudo_order_id']).agg({\n",
    "    'Order Date': 'first',\n",
    "    'Recipient Name': 'first'\n",
    "}).sort_values(by=['Recipient Name', 'Order Date']).reset_index()\n",
    "\n",
    "order_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for previous order date\n",
    "\n",
    "order_df['previous_order_date'] = order_df.groupby(by='Recipient Name')['Order Date'].shift(1)\n",
    "order_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate days since last order per customer\n",
    "\n",
    "order_df['days_since_last_order'] = order_df['Order Date'].sub(order_df['previous_order_date']).dt.days\n",
    "avg_days_since_last_order = order_df.groupby(by='Recipient Name')['days_since_last_order'].mean().sort_values()\n",
    "avg_days_since_last_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of average days between orders\n",
    "\n",
    "avg_days_counts = avg_days_since_last_order.value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Distribution of Average Days Since Last Order\", fontsize=16, fontweight='bold')\n",
    "plt.hist(avg_days_since_last_order, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Average Days Since Last Order', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "mean_avg_days = avg_days_since_last_order.mean()\n",
    "median_avg_days = avg_days_since_last_order.median()\n",
    "\n",
    "plt.axvline(mean_avg_days, color='red', linestyle='dashed', linewidth=1, label='Mean')\n",
    "plt.text(mean_avg_days*1.1, plt.ylim()[1]*0.8, np.round(mean_avg_days, 1), color='red', ha='center')\n",
    "plt.axvline(median_avg_days, color='blue', linestyle='dashed', linewidth=1, label='Median')\n",
    "plt.text(median_avg_days*1.15, plt.ylim()[1]*0.8, np.round(median_avg_days, 1), color='blue', ha='center')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* The *average number of days* between repeat orders is **54.2 days**.\n",
    "* The *median number of days* between repeat orders is **35 days**.\n",
    "* Distribution of average days between orders is also heavily **right-skewed**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "## Missing Customer Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect customer record columns\n",
    "\n",
    "customer_record_cols = ['Recipient Name', 'Recipient Email', 'Recipient Phone', 'Recipient Address', 'Recipient Postal Code', 'Recipient City', 'Recipient Region', 'Recipient Country']\n",
    "\n",
    "df[customer_record_cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of records missing for each customer record column\n",
    "\n",
    "np.round(df[customer_record_cols].isna().sum() / len(df) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect customer records with missing Recipient Name\n",
    "\n",
    "df[df['Recipient Name'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* **87%** of recipient address information is missing.\n",
    "* **50%** of recipient emails are missing.\n",
    "* **26%** of recipient names are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "# Time-Based Patterns\n",
    "\n",
    "- [x] Confirm dataset start and end dates\n",
    "- [x] Explore order volume by day of week\n",
    "- [x] Explore order volume by hour of day\n",
    "- [x] Look for seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "## Confirm dataset start and end dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify order date is datetime\n",
    "\n",
    "print(f\"Order Date is datetime: {is_datetime(df['Order Date'])}\")\n",
    "print(f\"Fulfillment Date is datetime: {is_datetime(df['Fulfillment Date'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series DataFrame with each row corresponding to one order and Order Date as index\n",
    "\n",
    "time_series_df = df.groupby('pseudo_order_id').agg({\n",
    "    'Order Date': 'first',\n",
    "    'Order Total': 'first'\n",
    "}).sort_values(by='Order Date').reset_index().set_index('Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series DataFrame with each row corresponding to one order and Fulfillment Date as index\n",
    "\n",
    "time_series_fulfillment_df = df.groupby('pseudo_order_id').agg({\n",
    "    'Fulfillment Date': 'first',\n",
    "    'Order Total': 'first'\n",
    "}).sort_values(by='Fulfillment Date').reset_index().set_index('Fulfillment Date')\n",
    "\n",
    "time_series_fulfillment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect time series DataFrame\n",
    "\n",
    "time_series_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print earliest and latest order date to confirm range\n",
    "\n",
    "print(f\"Earliest order date: {time_series_df.index.min()}\")\n",
    "print(f\"Latest order date: {time_series_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print earliest and latest order date to confirm range\n",
    "\n",
    "print(f\"Earliest order date: {time_series_fulfillment_df.index.min()}\")\n",
    "print(f\"Latest order date: {time_series_fulfillment_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* `Fulfillment Date` is missing for orders before **12/5/2023**.\n",
    "* `Order date` is available for all orders and spans the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "## Explore order volume by day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample frequency to daily and add day of week column\n",
    "\n",
    "day_of_week_orders = time_series_df.resample('D').size().reset_index(name='orders_count')\n",
    "day_of_week_orders['day_of_week'] = day_of_week_orders['Order Date'].dt.day_name()\n",
    "day_of_week_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average number of orders per day of week\n",
    "\n",
    "week_day_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "\n",
    "day_of_week_means = day_of_week_orders.groupby(by='day_of_week')['orders_count'].mean().reindex(week_day_order)\n",
    "day_of_week_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median number of orders per day of week\n",
    "\n",
    "day_of_week_medians = day_of_week_orders.groupby(by='day_of_week')['orders_count'].median().reindex(week_day_order)\n",
    "day_of_week_medians.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sales by day of the week\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "fig.suptitle('Orders per Day of Week', fontsize=16, fontweight='bold')\n",
    "\n",
    "day_of_week_means.plot(ax=ax[0])\n",
    "ax[0].set_title('Mean Orders', fontsize=14, fontweight='bold')\n",
    "ax[0].set_xlabel('', fontsize=12)\n",
    "\n",
    "day_of_week_medians.plot(ax=ax[1])\n",
    "ax[1].set_title('Median Orders', fontsize=14, fontweight='bold')\n",
    "ax[1].set_xlabel('', fontsize=12)\n",
    "\n",
    "fig.supylabel('Number of Orders', fontsize=12)\n",
    "fig.supxlabel('Day of Week', fontsize=12)\n",
    "\n",
    "ax[0].grid(visible=True, axis='both', linestyle='--', alpha=0.7)\n",
    "ax[1].grid(visible=True, axis='both', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* Trends between *mean* and *median* orders per day of week are similar.\n",
    "* **Fridays** have the highest number of orders, followed by **Tuesdays**.\n",
    "* Some orders have been taken on Sundays and Mondays, but this is irrelevant since they are outside business hours.\n",
    "* **Saturdays**, **Wednesdays**, and **Thursdays** share similar *mean* and *median* order quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "## Explore order volume by hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_fulfillment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to hourly frequency\n",
    "\n",
    "hour_of_day_orders = time_series_fulfillment_df.resample('h').size().reset_index(name='orders_count')\n",
    "\n",
    "hour_of_day_orders['hour_of_day'] = hour_of_day_orders['Fulfillment Date'].dt.hour\n",
    "hour_of_day_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and median orders per hour of day\n",
    "\n",
    "hour_of_day_means = hour_of_day_orders.groupby(by='hour_of_day')['orders_count'].mean()\n",
    "hour_of_day_totals = hour_of_day_orders.groupby('hour_of_day')['orders_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sales by hour\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "fig.suptitle('Orders per Hour of Day', fontsize=16, fontweight='bold')\n",
    "\n",
    "hour_of_day_means.plot(ax=ax[0])\n",
    "ax[0].set_title('Mean Orders', fontsize=14, fontweight='bold')\n",
    "ax[0].set_ylabel('Mean Orders', fontsize=12)\n",
    "ax[0].set_xlabel('')\n",
    "\n",
    "hour_of_day_totals.plot(ax=ax[1])\n",
    "ax[1].set_title('Total Orders', fontsize=14, fontweight='bold')\n",
    "ax[1].set_ylabel('Total Orders', fontsize=12)\n",
    "ax[1].set_xlabel('')\n",
    "\n",
    "fig.supxlabel('Hour of Day', fontsize=12)\n",
    "\n",
    "ax[0].grid(visible=True, axis='both', linestyle='--', alpha=0.7)\n",
    "ax[1].grid(visible=True, axis='both', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* `Order Date` does not store timestamp data, therefore `Fulfillment Date` was used to get hourly order data.\n",
    "* Peak order time is around **7pm**\n",
    "* Orders **decrease** closer to closing time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "## Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for weekly seasonality\n",
    "\n",
    "result = seasonal_decompose(day_of_week_orders['orders_count'], period=7)\n",
    "\n",
    "fig = result.plot()\n",
    "fig.set_size_inches(12, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* Since there are only **22** months worth of data, we cannot check for *monthly seasonality*.\n",
    "* Seasonal decomposition confirms that there is a **weekly** seasonal cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "# Menu and Product-Level Insights\n",
    "\n",
    "- [x] Count unique items sold\n",
    "- [x] Check for item categories (main, side, etc.)\n",
    "- [x] Rank top-selling items (by quantity, revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "## Unique Items Sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect quantity of unique item names\n",
    "\n",
    "print(f\"Number of unique item names: {len(df['Item Name'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique number of item and item variation combinations\n",
    "\n",
    "name_vars_counts = df.groupby(by='Item Name')['Item Variation'].nunique().sort_values(ascending=False).reset_index(name='count')\n",
    "print(f\"Number of unique item and variation combinations: {np.sum(name_vars_counts['count'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing Item Name\n",
    "\n",
    "df = df.dropna(subset='Item Name')\n",
    "df['Item Name'].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "* Belly Rubb offers **104** unique items based on `Item Name`.\n",
    "* **135** unique combinations of items and their variations have been sold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "## Item Aliases\n",
    "\n",
    "This section explores the various spellings for menu items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import item information for comparison\n",
    "\n",
    "items_df = pd.read_csv(RAW_DATA_DIR / 'MLW4W4RYAASNM_catalog-2025-08-26-2046.csv')\n",
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.fuzz import token_set_ratio\n",
    "\n",
    "def is_fuzzy_match(item_name: str, catalog_item: str, threshold: int = 85):\n",
    "    \"\"\"\n",
    "    Check if two items are a fuzzy match.\n",
    "\n",
    "    Params:\n",
    "        item_name (str): The name of the item to match.\n",
    "        catalog_item (str): The proper name of the item in the catalog.\n",
    "        threshold (int): The matching threshold (default is 85).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the items are a fuzzy match, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    return token_set_ratio(item_name.lower(), catalog_item.lower()) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create category feature\n",
    "\n",
    "items_df['category'] = items_df['Reporting Category'].str.split(\" \\(\", expand=True)[0]\n",
    "items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df['category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131",
   "metadata": {},
   "source": [
    "### NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df[items_df['category'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "#### Pulled Beef Sliders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134",
   "metadata": {},
   "source": [
    "This item is marked as `unavailable` on Square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulled_beef_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'Pulled Beef Sliders (12pcs)', threshold=71))]\n",
    "pulled_beef_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136",
   "metadata": {},
   "source": [
    "#### Pear+Gorgonzola Salad (Full Pan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137",
   "metadata": {},
   "source": [
    "This item is marked as `unavailable` on Square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "pear_full_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'Pear+Gorgonzola Salad (Full Pan)'))]\n",
    "pear_full_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Name'].str.lower().str.contains('pear')]['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140",
   "metadata": {},
   "source": [
    "### Party Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View party package catalog items\n",
    "\n",
    "party_packages = items_df[items_df['category'] == 'PARTY PACKAGE'].dropna(axis=1)\n",
    "party_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get party package orders\n",
    "\n",
    "party_package_orders = df.dropna(subset='Item Name')\n",
    "party_package_orders = party_package_orders[party_package_orders['Item Name'].apply(lambda x: is_fuzzy_match(x, 'party package'))]\n",
    "party_package_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143",
   "metadata": {},
   "source": [
    "#### Party Package (10-12 ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 10-12ppl party package orders\n",
    "\n",
    "party_package_ten = df.dropna(subset='Item Name')\n",
    "\n",
    "party_package_ten = party_package_ten[party_package_ten['Item Name'].apply(lambda x: is_fuzzy_match(x, 'Party Package (10-12ppl)', threshold=92))]\n",
    "party_package_ten['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect differences in order date and price\n",
    "\n",
    "party_package_ten.groupby(by='Item Name').agg(\n",
    "    min_order_date = ('Order Date', 'min'),\n",
    "    max_order_date = ('Order Date', 'max'),\n",
    "    item_price = ('Order Date', 'first')\n",
    ").sort_values(by='min_order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_package_ten['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect outlier\n",
    "\n",
    "df[df['Item Name'] == 'Party Package (10-12ppl)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148",
   "metadata": {},
   "source": [
    "* There is **one** order of this party package with no space in *(10-12 ppl)*.\n",
    "    * This is the first and only order with that alias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149",
   "metadata": {},
   "source": [
    "#### Party Package (6-8 ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get orders of party package (6-8 ppl)\n",
    "\n",
    "party_package_six = df.dropna(subset='Item Name')\n",
    "\n",
    "party_package_six = party_package_six[party_package_six['Item Name'].apply(lambda x: is_fuzzy_match(x, 'Party Package (6-8 ppl)', threshold=92))]\n",
    "party_package_six['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect order date and price differences between aliases\n",
    "\n",
    "party_package_six.groupby(by='Item Name').agg(\n",
    "    min_order_date = ('Order Date', 'min'),\n",
    "    max_order_date = ('Order Date', 'max'),\n",
    "    item_price = ('Item Price', 'first')\n",
    ").sort_values(by='min_order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect outlier order with an extra space\n",
    "\n",
    "df[df['Item Name'] == 'Party Package  (6-8 ppl)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_package_six['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154",
   "metadata": {},
   "source": [
    "* There is an **extra space** in the most recent order of the *Party Package (6-8 ppl)*.\n",
    "    * Since it is only one order and it is placed through a *Payment Link*, it is likely a manual entry typo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155",
   "metadata": {},
   "source": [
    "#### Party Package (4-6 ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get party package (4-6 ppl) orders\n",
    "\n",
    "party_package_four = df.dropna(subset='Item Name')\n",
    "\n",
    "party_package_four = party_package_four[party_package_four['Item Name'].apply(lambda x: is_fuzzy_match(x, 'Party Package (4-6 ppl)', threshold=92))]\n",
    "party_package_four['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View order dates and prices for party package (4-6ppl) orders\n",
    "\n",
    "party_package_four.groupby(by='Item Name').agg(\n",
    "    min_order_date = ('Order Date', 'min'),\n",
    "    max_order_date = ('Order Date', 'max'),\n",
    "    item_price = ('Item Price', 'first')\n",
    ").sort_values(by='min_order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get outlier order\n",
    "\n",
    "df[df['Item Name'] == 'PARTY PACKAGE (4-6ppl)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_package_four['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160",
   "metadata": {},
   "source": [
    "* There is a single order with the alias `PARTY PACKAGE (4-6ppl)`.\n",
    "*   Otherwise orders match catalog naming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {},
   "source": [
    "### Desserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dessert items\n",
    "\n",
    "dessert_catalog = items_df[items_df['category'] == 'DESSERTS'].dropna(axis=1)\n",
    "dessert_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163",
   "metadata": {},
   "source": [
    "There are only two desserts on the menu, `CHEESECAKE BITES` and `MARSH'n'COOKIE`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164",
   "metadata": {},
   "source": [
    "#### Marsh'n'Cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "marsh_orders = df.dropna(subset='Item Name')\n",
    "\n",
    "marsh_orders = marsh_orders[marsh_orders['Item Name'].apply(lambda x: is_fuzzy_match(x, \"MARSH'n'COOKIE\", threshold=70))]\n",
    "marsh_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "marsh_orders['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "marsh_orders['Order Date'].aggregate(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168",
   "metadata": {},
   "source": [
    "#### Cheesecake Bites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cheesecake orders\n",
    "\n",
    "cheesecake_orders = df.dropna(subset='Item Name')\n",
    "\n",
    "cheesecake_orders = cheesecake_orders[cheesecake_orders['Item Name'].apply(lambda x: is_fuzzy_match(x, 'CHEESECAKE', threshold=70))]\n",
    "cheesecake_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect variations\n",
    "\n",
    "cheesecake_orders['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect earliest and latest order dates\n",
    "\n",
    "cheesecake_orders['Order Date'].aggregate(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172",
   "metadata": {},
   "source": [
    "### Sips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "sips = items_df[items_df['category'] == 'SIPS']\n",
    "sips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get drink orders\n",
    "\n",
    "sips_items = sips['Item Name'].values\n",
    "\n",
    "sips_orders = df[df['Item Name'].isin(sips_items)]\n",
    "sips_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are other spellings of items\n",
    "\n",
    "for item in sips_items:\n",
    "    print(df[df['Item Name'].dropna().apply(lambda x: is_fuzzy_match(x, item, threshold=70))]['Item Name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176",
   "metadata": {},
   "source": [
    "Since drink orders map perfectly to the menu catalog, there is no need to create standardization entries for them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177",
   "metadata": {},
   "source": [
    "### Dips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get menu items in DIPS category\n",
    "\n",
    "dips_items = items_df[items_df['category'] == 'DIPS']\n",
    "dips_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179",
   "metadata": {},
   "source": [
    "Each dip has two versions, one seemingly standard size, and one *8 OZ* size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orders with sauce or dip in Item Name\n",
    "\n",
    "df[df['Item Name'].str.lower().str.contains('sauce|dip')]['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181",
   "metadata": {},
   "source": [
    "* `CHUNKY BLUE CHEESE DIP`, `BLUE CHEESE SAUCE`, `SWEET AND SPICY BBQ SAUCE`, `SIGNATURE BBQ SAUCE`, `HOUSE-MADE CURRY DIP`, `TANGY & SWEET CURRY DIP`, and `BBQ dipping sauce` are not in the menu catalog.\n",
    "    * `SIGNATURE BBQ SAUCE` is very similar to `SIGNATURE BBQ DIP`.\n",
    "    * `SWEET AND SPICY BBQ SAUCE` is very similar to `SWEET AND SPICY BBQ DIP`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182",
   "metadata": {},
   "source": [
    "#### Curry Dip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183",
   "metadata": {},
   "source": [
    "The curry dip has been seemingly taken off the menu since it only exists in orders and not the current catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select curry dip orders\n",
    "\n",
    "curry_dip = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'CURRY DIP', threshold=70))]\n",
    "curry_dip['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm order dates\n",
    "\n",
    "curry_dip['Order Date'].aggregate(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186",
   "metadata": {},
   "outputs": [],
   "source": [
    "curry_dip['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187",
   "metadata": {},
   "source": [
    "#### Sweet and Spicy BBQ Dip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweet and spicy catalog items\n",
    "\n",
    "ss_bbq_catalog = items_df[items_df['Item Name'].str.lower().str.contains('spicy')].dropna(axis=1)\n",
    "ss_bbq_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189",
   "metadata": {},
   "source": [
    "Similar to the other dip items, the *8 oz* version is **$3.50** while the standard version is **$1.45**.\n",
    "The *8 oz* version is also labeled a **Sauce**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_bbq_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'sweet and spicy', threshold=70))]\n",
    "ss_bbq_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_bbq_orders['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192",
   "metadata": {},
   "source": [
    "#### Signature BBQ Dip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View signature bbq dip catalog items\n",
    "\n",
    "bbq_dip_catalog = items_df[items_df['Item Name'].str.lower().str.contains('signature')].dropna(axis=1)\n",
    "bbq_dip_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect prices\n",
    "\n",
    "bbq_dip_catalog[['Item Name', 'Price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195",
   "metadata": {},
   "source": [
    "The only differences between the two entries are: \n",
    "* The *8 oz* version costs **$3.50** while the standard costs **$1.45**.\n",
    "* The *8 oz* version is titled `SIGNATURE BBQ DIP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get orders of signature bbq dip\n",
    "\n",
    "bbq_dip_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'SIGNATURE BBQ DIP', threshold=70))]\n",
    "bbq_dip_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare order dates and prices\n",
    "\n",
    "bbq_dip_orders.groupby(by='Item Name').agg(\n",
    "    min_order_date = ('Order Date', 'min'),\n",
    "    max_order_date = ('Order Date', 'max'),\n",
    "    price = ('Item Price', 'first')\n",
    ").sort_values(by='min_order_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198",
   "metadata": {},
   "source": [
    "`BBQ dipping sauce` and `SIGNATURE BBQ SAUCE` ARE the same items as `SIGNATURE BBQ DIP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbq_dip_orders['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200",
   "metadata": {},
   "source": [
    "#### Pickled Jalapeno Peppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pickled jalapeno pepper catalog items\n",
    "\n",
    "peppers_catalog = items_df[items_df['Item Name'].str.lower().str.contains('pickled')]\n",
    "peppers_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select pickled jalapeno orders\n",
    "\n",
    "peppers_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'PICKLED JALAPEO PEPPERS', threshold=70))]\n",
    "peppers_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect variations\n",
    "\n",
    "peppers_orders['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204",
   "metadata": {},
   "source": [
    "#### Mayonnaise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": [
    "mayonnaise_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'MAYONNAISE'))]\n",
    "mayonnaise_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206",
   "metadata": {},
   "outputs": [],
   "source": [
    "mayonnaise_orders['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207",
   "metadata": {},
   "source": [
    "#### Mustard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208",
   "metadata": {},
   "outputs": [],
   "source": [
    "mustard_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'MUSTARD'))]\n",
    "mustard_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209",
   "metadata": {},
   "outputs": [],
   "source": [
    "mustard_orders['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210",
   "metadata": {},
   "source": [
    "#### Ketchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ketchup orders\n",
    "\n",
    "ketchup_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'ketchup', threshold=75))]\n",
    "ketchup_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "ketchup_orders['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213",
   "metadata": {},
   "source": [
    "#### Creamy Blue Cheese Dip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214",
   "metadata": {},
   "source": [
    "No larger size of the *Creamy Blue Cheese Dip* is offered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get orders of the creamy blue cheese dip\n",
    "\n",
    "blue_cheese_dip = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, \"CREAMY BLUE CHEESE DIP\", threshold=75))]\n",
    "blue_cheese_dip['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare order dates and prices for different blue cheese orders\n",
    "\n",
    "blue_cheese_dip.groupby(by='Item Name').agg(\n",
    "    min_order_date = ('Order Date', 'min'),\n",
    "    max_order_date = ('Order Date', 'max'),\n",
    "    price = ('Item Price', 'first')\n",
    ").sort_values(by='min_order_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_cheese_dip['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218",
   "metadata": {},
   "source": [
    "#### Ranch Dip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranch dip menu items\n",
    "\n",
    "ranch_dip_catalog = items_df[items_df['Item Name'].str.lower().str.contains('ranch')].dropna(axis=1)\n",
    "ranch_dip_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranch_dip_catalog[['Item Name', 'Price', 'Shipping Enabled', 'Delivery Enabled', 'Pickup Enabled']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221",
   "metadata": {},
   "source": [
    "* The 8 oz version of ranch is called `Classy Ranch Sauce (8 oz)`, vs the regular being `CLASSY RANCH DIP`.\n",
    "* The 8 oz version costs **$3.50**, vs. the standard **$1.45**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ranch orders\n",
    "\n",
    "ranch_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'CLASSY RANCH DIP')) | df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'Classy Ranch Sauce (8 oz)'))]\n",
    "ranch_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List unique aliases for ranch orders\n",
    "\n",
    "ranch_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect outlier ranch order alias\n",
    "\n",
    "ranch_orders[ranch_orders['Item Name'] == 'Ranch (8 oz)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225",
   "metadata": {},
   "source": [
    "The `Item Price` is the same for ranch orders with the name `Randh (8 oz)`, which differs from those listed in the catalog. Therefore, it is safe to assume that these refer to the same item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226",
   "metadata": {},
   "source": [
    "#### Boom-Boom Sauce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get boom-boom sauce items from menu catalog\n",
    "\n",
    "boom_catalog = dips_items[dips_items['Item Name'].str.contains('BOOM-BOOM SAUCE')].dropna(axis=1)\n",
    "boom_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differences between the two boom-boom sauce items\n",
    "\n",
    "boom_catalog[['Item Name', 'Price', 'Shipping Enabled', 'Delivery Enabled', 'Pickup Enabled']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229",
   "metadata": {},
   "source": [
    "* The **8 OZ** listing is priced higher at **$3.50**.\n",
    "* `Shipping Enabled` is **True** for the *8 oz* listing, but both `Delivery Enabled` and `Pickup Enabled` are **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get orders of boom-boom sauce\n",
    "\n",
    "boom_orders = df[df['Item Name'].apply(lambda x: is_fuzzy_match(x, 'BOOM-BOOM SAUCE'))]\n",
    "boom_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variations\n",
    "\n",
    "boom_orders['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check order dates\n",
    "\n",
    "boom_orders['Order Date'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233",
   "metadata": {},
   "source": [
    "### Sandwiches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List catalog items in SANDWICHES category\n",
    "\n",
    "items_df[items_df['category'] == 'SANDWICHES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List unique item names in orders dataset with sandwich in the name\n",
    "\n",
    "df[df['Item Name'].str.lower().str.contains('sandwich', na=False)]['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236",
   "metadata": {},
   "source": [
    "There are some inconsistencies between *order* data and *catalog* data:\n",
    "* `CIABATTA STEAK SANDWICH`, `1/2 POUND STEAK SANDWICH`, `CHIABATTA STEAK SANDWICH`, and `ULTIMATE STEAK SANDWICH` don't exist in the current catalog.\n",
    "* `Crispy Chicken Sandwich` does not exist in the catalog since there it is fully uppercase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237",
   "metadata": {},
   "source": [
    "#### Pulled Beef Sandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get orders of pulled beef sandwiches\n",
    "\n",
    "pulled_beef = df[df['Item Name'].str.contains('PULLED BEEF SANDWICH', na=False)]\n",
    "pulled_beef.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulled_beef['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240",
   "metadata": {},
   "source": [
    "This item is a **new** addition to the menu and therefore matches the catalog entry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241",
   "metadata": {},
   "source": [
    "#### Steak Sandwiches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242",
   "metadata": {},
   "outputs": [],
   "source": [
    "steak_sandwich_aliases = [\n",
    "    'CIABATTA STEAK SANDWICH',\n",
    "    '1/2 POUND STEAK SANDWICH',\n",
    "    'CHIABATTA STEAK SANDWICH',\n",
    "    'ULTIMATE STEAK SANDWICH',\n",
    "    'STEAK SANDWICH']\n",
    "\n",
    "steak_sandwiches = df[df['Item Name'].isin(steak_sandwich_aliases)]\n",
    "steak_sandwiches.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect order dates and prices for steak sandwich item names\n",
    "\n",
    "steak_sandwiches.groupby(by='Item Name').agg(\n",
    "    min_order_date = ('Order Date', 'min'),\n",
    "    max_order_date = ('Order Date', 'max'),\n",
    "    item_price = ('Item Price', 'first')\n",
    ").sort_values(by='min_order_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244",
   "metadata": {},
   "source": [
    "* It looks like these 5 aliases for the `STEAK SANDWICH` correspond to each other.\n",
    "    * The `Item Price` is **$15.45** until it increases for the `CIABATTA STEAK SANDWICH` TO **$19.45**.\n",
    "    * The `Order Date` for the items lines up with no overlapping dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect item variations\n",
    "\n",
    "steak_sandwiches['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246",
   "metadata": {},
   "source": [
    "#### Crispy Chicken Sandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken_sandwich = df.dropna(subset='Item Name')\n",
    "\n",
    "chicken_sandwich = chicken_sandwich[chicken_sandwich['Item Name'].str.lower().str.contains('chicken sandwich', na=False)]\n",
    "chicken_sandwich.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outlier alias\n",
    "\n",
    "df[df['Item Name'] == 'Crispy Chicken Sandwich']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249",
   "metadata": {},
   "source": [
    "The very first order of the *crispy chicken sandwich* had the outlier alias. The others follow the exact format of the catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250",
   "metadata": {},
   "source": [
    "### Combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of items in catalog with COMBOS category\n",
    "\n",
    "items_df[items_df['category'] == 'COMBOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of orders with combo in item name\n",
    "\n",
    "combo_keywords = ['combo', 'deal', 'bundle']\n",
    "\n",
    "orders_combo = df[(df['Item Name'].str.lower().str.contains('|'.join(combo_keywords), na=False)) | (df['Item Name'] == 'WINGS & FRIES')]\n",
    "orders_combo['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_combo['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254",
   "metadata": {},
   "source": [
    "When comparing the list of combos in the menu catalog with orders with the name *combo* in them, there are some discrepancies:\n",
    "* `BABY BACK RIB COMBO`, `THE BELLY COMBO`, `BBQ RIB COMBO`, `THE BABY BACK COMBO`, `BABYBACK RIB COMBO`, `WINGS COMBO`, `RIBS & WINGS BUNDLE !BEEF RIBS ONLY!`, AND `BEEF SANDWICH COMBO` are present in orders by not in the catalog.\n",
    "* Each combo in the catalog only has a `Regular` variation option, but orders have **two** other possible variations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255",
   "metadata": {},
   "source": [
    "#### The Belly Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Belly combo\n",
    "\n",
    "belly_combo = df.dropna(subset='Item Name')\n",
    "\n",
    "belly_combo = belly_combo[belly_combo['Item Name'] == 'THE BELLY COMBO']\n",
    "belly_combo.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257",
   "metadata": {},
   "outputs": [],
   "source": [
    "belly_combo.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258",
   "metadata": {},
   "source": [
    "* `THE BELLY COMBO` only existed in *2024*.\n",
    "* It does not appear like it was updated with a different alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259",
   "metadata": {},
   "outputs": [],
   "source": [
    "belly_combo['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260",
   "metadata": {},
   "source": [
    "#### Wings & Fries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wings & Fries\n",
    "\n",
    "wings_and_fries = df.dropna(subset='Item Name')\n",
    "\n",
    "wings_and_fries = wings_and_fries[wings_and_fries['Item Name'] == 'WINGS & FRIES']\n",
    "wings_and_fries.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262",
   "metadata": {},
   "outputs": [],
   "source": [
    "wings_combo = df.dropna(subset='Item Name')\n",
    "\n",
    "wings_combo = wings_combo[wings_combo['Item Name'] == 'WINGS COMBO']\n",
    "wings_combo.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263",
   "metadata": {},
   "outputs": [],
   "source": [
    "wings_combo['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264",
   "metadata": {},
   "outputs": [],
   "source": [
    "wings_and_fries['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265",
   "metadata": {},
   "source": [
    "#### Steak Sandwich Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steak sandwich combo\n",
    "\n",
    "steak_sandwich_combo = df.dropna(subset='Item Name')\n",
    "\n",
    "steak_sandwich_combo = steak_sandwich_combo[steak_sandwich_combo['Item Name'] == 'STEAK SANDWICH COMBO']\n",
    "steak_sandwich_combo.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267",
   "metadata": {},
   "outputs": [],
   "source": [
    "steak_sandwich_combo['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268",
   "metadata": {},
   "outputs": [],
   "source": [
    "steak_sandwich_combo['Order Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269",
   "metadata": {},
   "outputs": [],
   "source": [
    "beef_sandwich_combo = df.dropna(subset='Item Name')\n",
    "\n",
    "beef_sandwich_combo = beef_sandwich_combo[beef_sandwich_combo['Item Name'] == 'BEEF SANDWICH COMBO']\n",
    "beef_sandwich_combo.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270",
   "metadata": {},
   "outputs": [],
   "source": [
    "beef_sandwich_combo['Item Variation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271",
   "metadata": {},
   "outputs": [],
   "source": [
    "steak_sandwich_combo['Item Price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272",
   "metadata": {},
   "source": [
    "There is only **one** order of `BEEF SANDWICH COMBO` which has the same `Item Price` as the initial price of the `STEAK SANDWICH COMBO`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273",
   "metadata": {},
   "source": [
    "#### Pulled Sandwich Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulled sandwich combo\n",
    "\n",
    "pulled_sandwich_combo = df.dropna(subset='Item Name')\n",
    "\n",
    "pulled_sandwich_combo = pulled_sandwich_combo[pulled_sandwich_combo['Item Name'] == 'PULLED SANDWICH COMBO']\n",
    "pulled_sandwich_combo.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulled_sandwich_combo['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276",
   "metadata": {},
   "source": [
    "Since this is a newer addition to the menu, *catalog* and *order* data match perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277",
   "metadata": {},
   "source": [
    "#### Pork Rack Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pork rack combo\n",
    "\n",
    "pork_rack_combo = df.dropna(subset='Item Name')\n",
    "\n",
    "pork_rack_combo = pork_rack_combo[pork_rack_combo['Item Name'] == 'PORK RACK COMBO']\n",
    "pork_rack_combo.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279",
   "metadata": {},
   "outputs": [],
   "source": [
    "pork_rack_combo['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280",
   "metadata": {},
   "source": [
    "Since this is a newer addition to the menu, *catalog* and *order* data match perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281",
   "metadata": {},
   "source": [
    "#### Crispy Chicken Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crispy chicken combo\n",
    "\n",
    "crispy_chicken_combo = df.dropna(subset='Item Name')\n",
    "\n",
    "crispy_chicken_combo = crispy_chicken_combo[crispy_chicken_combo['Item Name'] == 'CRISPY CHICKEN COMBO']\n",
    "crispy_chicken_combo.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283",
   "metadata": {},
   "outputs": [],
   "source": [
    "crispy_chicken_combo['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284",
   "metadata": {},
   "source": [
    "Since this is a newer addition to the menu, data in *orders* and the *catalog* match perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285",
   "metadata": {},
   "source": [
    "#### Ribs & Wings Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ribs & wings bundle\n",
    "\n",
    "ribs_wings_bundle = df.dropna(subset='Item Name')\n",
    "\n",
    "ribs_wings_bundle = ribs_wings_bundle[ribs_wings_bundle['Item Name'] == 'RIBS & WINGS BUNDLE']\n",
    "ribs_wings_bundle.sort_values(by='Order Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect variant of ribs & wings bundle\n",
    "\n",
    "df[df['Item Name'] == 'RIBS & WINGS BUNDLE !BEEF RIBS ONLY!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288",
   "metadata": {},
   "source": [
    "Since there is only **one** order of the `RIBS & WINGS BUNDLE !BEEF RIBS ONLY!`, we'll standardize it to a regular order of the bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289",
   "metadata": {},
   "source": [
    "#### Baby Back Rib Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290",
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_back_combo = df.dropna(subset='Item Name')\n",
    "\n",
    "# Use fuzzy matching to find similar item names\n",
    "baby_back_combo['is_baby_back_rib_combo'] = baby_back_combo['Item Name'].apply(lambda x: is_fuzzy_match(x, 'BABY BACK RIB COMBO'))\n",
    "baby_back_combo = baby_back_combo[baby_back_combo['is_baby_back_rib_combo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291",
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_back_combo['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare order dates for three variants of the combo name\n",
    "\n",
    "baby_back_combo.groupby(by='Item Name').agg(\n",
    "    min_order_date = ('Order Date', 'min'),\n",
    "    max_order_date = ('Order Date', 'max'),\n",
    "    item_price = ('Item Price', 'first')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293",
   "metadata": {},
   "source": [
    "* *Baby Back Rib Combo* items range in date from `2023-12-09` to `2025-04-29`.\n",
    "* There is a significant gap between `THE BABY BACK COMBO` and `BABYBACK RIB COMBO` implying there may be another alias for that combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine orders between THE BABY BACK COMBO and BABYBACK RIB COMBO\n",
    "\n",
    "min_date = pd.to_datetime('2024-02-28')\n",
    "max_date = pd.to_datetime('2024-04-09')\n",
    "\n",
    "between_orders = df[df['Order Date'].between(min_date, max_date, inclusive='neither')]\n",
    "between_orders.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for combos\n",
    "\n",
    "between_orders['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select BBQ RIB COMBO orders\n",
    "\n",
    "bbq_rib_combo = df[df['Item Name'] == 'BBQ RIB COMBO'].sort_values(by='Order Date')\n",
    "bbq_rib_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect order dates and item prices\n",
    "\n",
    "bbq_rib_combo[['Order Date', 'Item Price']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select THE BELLY COMBO orders\n",
    "\n",
    "belly_combo = df[df['Item Name'] == 'THE BELLY COMBO'].sort_values(by='Order Date')\n",
    "belly_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect order dates and item prices\n",
    "\n",
    "belly_combo[['Order Date', 'Item Price']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300",
   "metadata": {},
   "source": [
    "* There are **3** aliases for Baby Back Rib combos: `BABY BACK RIB COMBO`, `BABYBACK RIB COMBO`, and `THE BABY BACK COMBO`.\n",
    "    * It is **highly likely** that `BBQ RIB COMBO` is another alias because it fills in the gap in orders and is the same price.\n",
    "* `THE BELLY COMBO` **is not** an alias because those orders coincide with the other *baby back rib combo* orders.\n",
    "\n",
    "The `Item Description` for the `3-BONE MEAL DEAL` states: *Flying solo, or want to get it all for one? Well, this ones for you! Get three, juicy, baby back pork rib bones with two sides of your choosing. Includes complementary pickled peppers, signature BBQ sauce dip, and a beverage!*\n",
    "This implies that the `3-BONE MEAL DEAL` is the latest version of the baby back rib combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variations\n",
    "\n",
    "bbq_rib_combo_aliases = [\"3-BONE MEAL DEAL\", \"BABY BACK RIB COMBO\", \"THE BABY BACK COMBO\", \"BABYBACK RIB COMBO\", \"BBQ RIB COMBO\"]\n",
    "df[df['Item Name'].isin(bbq_rib_combo_aliases)]['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outlier variations\n",
    "\n",
    "df[(df['Item Variation'] == 'Crinkle Fries- Truffle Salt, Mac&Cheese') | (df['Item Variation'] == 'Crinkle Fries- Rosemary Pepper')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303",
   "metadata": {},
   "source": [
    "Since there are only two orders with `Item Variation` which seems to specify sides and seasonings, we'll standardize them to `Regular`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304",
   "metadata": {},
   "source": [
    "#### Beef Rack Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get orders of beef rack combo\n",
    "\n",
    "beef_rack = df.dropna(subset='Item Name')\n",
    "\n",
    "# Use fuzzy matching to get orders\n",
    "beef_rack['is_beef_rack_combo'] = beef_rack['Item Name'].apply(lambda x: is_fuzzy_match(x, 'BEEF RACK COMBO'))\n",
    "beef_rack = beef_rack[beef_rack['is_beef_rack_combo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check item names\n",
    "\n",
    "beef_rack['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variations\n",
    "\n",
    "beef_rack['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check order dates for beef racks\n",
    "\n",
    "beef_rack['Order Date'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309",
   "metadata": {},
   "source": [
    "#### 3-Bone Meal Deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get orders of three bone combo\n",
    "\n",
    "three_bone = df.dropna(subset='Item Name')\n",
    "\n",
    "# Use fuzzy matching to get orders\n",
    "three_bone['is_three_bone_combo'] = three_bone['Item Name'].apply(lambda x: is_fuzzy_match(x, '3-BONE MEAL DEAL'))\n",
    "three_bone = three_bone[three_bone['is_three_bone_combo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique item names for three bone combo\n",
    "\n",
    "three_bone['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variations\n",
    "\n",
    "three_bone['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dates\n",
    "\n",
    "three_bone['Order Date'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314",
   "metadata": {},
   "source": [
    "As discovered while exploring *baby back rib combo* orders, this is the most up-to-date alias for baby back rib combo orders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315",
   "metadata": {},
   "source": [
    "### Bites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of items in catalog for BITES category\n",
    "\n",
    "items_df[items_df['category'] == 'BITES']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317",
   "metadata": {},
   "source": [
    "#### Pork Belly Bites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318",
   "metadata": {},
   "outputs": [],
   "source": [
    "bites = df.dropna(subset='Item Name')\n",
    "bites = bites[bites['Item Name'].str.lower().str.contains('bite')]\n",
    "\n",
    "bites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319",
   "metadata": {},
   "outputs": [],
   "source": [
    "bites['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320",
   "metadata": {},
   "outputs": [],
   "source": [
    "belly_bites = bites[bites['Item Name'] == 'BELLY BITES']\n",
    "belly_bites['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321",
   "metadata": {},
   "outputs": [],
   "source": [
    "pork_belly_bites = bites[bites['Item Name'] == 'PORK BELLY BITES']\n",
    "pork_belly_bites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322",
   "metadata": {},
   "outputs": [],
   "source": [
    "pork_belly_bites['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df[items_df['Item Name'] == 'PORK BELLY BITES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last order date of pork belly bites\n",
    "\n",
    "print(f\"Last order of pork belly bites: {belly_bites['Order Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325",
   "metadata": {},
   "outputs": [],
   "source": [
    "belly_bites.sort_values(by='Order Date').tail(1)['Item Variation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326",
   "metadata": {},
   "source": [
    "* **Belly bites** was recently updated to `PORK BELLY BITES`.\n",
    "* `Item Variation` was accordingly updated to only a single value, **Regular**.\n",
    "    * Previous variation values will be standardized to **regular**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327",
   "metadata": {},
   "source": [
    "#### Mozzarella Sticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset='Item Name')\n",
    "df[df['Item Name'].str.lower().str.contains('wedge')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sticks = df.dropna(subset='Item Name')\n",
    "sticks = sticks[sticks['Item Name'].str.lower().str.contains('stick')]\n",
    "\n",
    "sticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330",
   "metadata": {},
   "outputs": [],
   "source": [
    "sticks['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331",
   "metadata": {},
   "outputs": [],
   "source": [
    "sticks['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df[items_df['Item Name'].str.lower().str.contains('stick')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333",
   "metadata": {},
   "source": [
    "#### Grilled Sweet Corn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334",
   "metadata": {},
   "outputs": [],
   "source": [
    "corn = df.dropna(subset='Item Name')\n",
    "corn = corn[corn['Item Name'].str.lower().str.contains('corn')]\n",
    "\n",
    "corn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335",
   "metadata": {},
   "outputs": [],
   "source": [
    "corn['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336",
   "metadata": {},
   "outputs": [],
   "source": [
    "corn['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df[items_df['Item Name'].str.lower().str.contains('corn')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338",
   "metadata": {},
   "source": [
    "#### Chicken Wings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339",
   "metadata": {},
   "outputs": [],
   "source": [
    "wings = df.dropna(subset='Item Name')\n",
    "wings = wings[wings['Item Name'].str.lower().str.contains('wing')]\n",
    "\n",
    "wings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of items including wings\n",
    "\n",
    "wings['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See list of wings in catalog that are in BITES category\n",
    "\n",
    "items_df[(items_df['Item Name'].str.lower().str.contains('wing')) & (items_df['category'] == 'BITES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of orders per kind of wings\n",
    "\n",
    "bites_wings = ['CHICKEN WINGS', 'FRIED CHICKEN WINGS']\n",
    "wings = wings[wings['Item Name'].isin(bites_wings)]\n",
    "\n",
    "wings['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect order dates for different aliases\n",
    "\n",
    "wings.groupby(by='Item Name')['Order Date'].agg(['count', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List variations\n",
    "\n",
    "wings['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345",
   "metadata": {},
   "source": [
    "* Chicken wings menu item changed to `FRIED CHICKEN WINGS` in **June 2025**.\n",
    "* `Item Variation` stays consistent between orders and catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346",
   "metadata": {},
   "source": [
    "### Sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of Sides\n",
    "\n",
    "items_df[items_df['category'] == 'SIDES']['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348",
   "metadata": {},
   "source": [
    "#### Pineapple Slaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create slaw dataframe\n",
    "\n",
    "slaw_df = df.dropna(subset='Item Name')\n",
    "slaw_df = slaw_df[slaw_df['Item Name'].str.lower().str.contains('slaw')]\n",
    "\n",
    "slaw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check item name aliase\n",
    "\n",
    "slaw_df['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of orders with each alias\n",
    "\n",
    "slaw_df['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect alias with one order\n",
    "\n",
    "slaw_df[slaw_df['Item Name'] == 'Pineapple Coleslaw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique variations\n",
    "\n",
    "slaw_df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with catalog options\n",
    "\n",
    "items_df[items_df['Item Name'].str.lower().str.contains('slaw')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect variations that don't exist in current catalog\n",
    "\n",
    "slaw_df[(slaw_df['Item Variation'] == '8 oz.') | (slaw_df['Item Variation'] == '4 oz.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356",
   "metadata": {},
   "source": [
    "* The alias for pineapple coleslaw changed to **all caps** after the first order.\n",
    "* Only the first two orders contains variations `8 oz.` and `4 oz.`.\n",
    "    * The current variations in the catalog are `Side` and `Full`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357",
   "metadata": {},
   "source": [
    "#### Pear Gorgonzola Salad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create salad dataframe\n",
    "\n",
    "salad_df = df.dropna(subset='Item Name')\n",
    "salad_df = salad_df[salad_df['Item Name'].str.lower().str.contains('salad')]\n",
    "\n",
    "salad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of aliases\n",
    "\n",
    "salad_df['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of variations\n",
    "\n",
    "salad_df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm with catalog\n",
    "\n",
    "items_df[items_df['Item Name'] == 'PEAR GORGONZOLA SALAD']['Variation Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362",
   "metadata": {},
   "source": [
    "#### Baked Baby Potatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baked potatoes dataframe\n",
    "\n",
    "potatoes_df = df.dropna(subset='Item Name')\n",
    "potatoes_df = potatoes_df[potatoes_df['Item Name'].str.lower().str.contains('potato')]\n",
    "\n",
    "potatoes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List unique item names\n",
    "\n",
    "potatoes_df['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List unique variations\n",
    "\n",
    "potatoes_df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm possible variations with catalog\n",
    "\n",
    "items_df[items_df['Item Name'] == 'BAKED BABY POTATOES']['Variation Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367",
   "metadata": {},
   "source": [
    "#### Mac and Cheese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mac and cheese dataframe\n",
    "\n",
    "mac_df = df.dropna(subset=['Item Name'])\n",
    "mac_df = mac_df[mac_df['Item Name'].str.lower().str.contains('mac')]\n",
    "\n",
    "mac_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate items\n",
    "\n",
    "mac_df['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List possible variations\n",
    "\n",
    "mac_df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect family size and pan orders\n",
    "\n",
    "mac_pan = mac_df[(mac_df['Item Name'] == 'MacnCheese Family size') | (mac_df['Item Name'] == 'MacnCheese Half Pan')]\n",
    "\n",
    "mac_pan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of orders of each variation\n",
    "\n",
    "mac_df['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect alias\n",
    "\n",
    "mac_df[mac_df['Item Name'] == 'Artisan Mac and Cheese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View order dates per item\n",
    "\n",
    "mac_df.groupby(by='Item Name')['Order Date'].agg(['min', 'max', 'count']).sort_values(by='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375",
   "metadata": {},
   "source": [
    "#### Fries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df[items_df['Item Name'].str.lower().str.contains('fries')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377",
   "metadata": {},
   "outputs": [],
   "source": [
    "fries_df = df.dropna(subset=['Item Name'])\n",
    "\n",
    "fries_df = fries_df[fries_df['Item Name'].str.lower().str.contains('fries')]\n",
    "fries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique item names for fries\n",
    "\n",
    "fries_df['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List variations\n",
    "\n",
    "fries_df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380",
   "metadata": {},
   "outputs": [],
   "source": [
    "fries_df[['Item Name', 'Item Variation']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of orders for each unique item name\n",
    "\n",
    "fries_df['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382",
   "metadata": {},
   "outputs": [],
   "source": [
    "fries_df[fries_df['Item Name'] == 'LOAD YOUR FRIES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect min and max order dates for fries\n",
    "\n",
    "fries_dates = fries_df.groupby(by='Item Name')['Order Date'].agg(['min', 'max', 'count']).reset_index()\n",
    "fries_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384",
   "metadata": {},
   "outputs": [],
   "source": [
    "fries_dates['in_catalog'] = fries_dates['Item Name'].isin(items_df['Item Name'])\n",
    "fries_dates.sort_values(by='in_catalog', inplace=True)\n",
    "fries_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385",
   "metadata": {},
   "outputs": [],
   "source": [
    "crinkle_orders = fries_df[fries_df['Item Name'] == 'CRINKLE FRIES']\n",
    "crinkle_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386",
   "metadata": {},
   "outputs": [],
   "source": [
    "crispy_fries = fries_df[fries_df['Item Name'] == 'CRISPY  FRIES']\n",
    "crispy_fries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387",
   "metadata": {},
   "source": [
    "##### Loaded Fries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_orders = fries_df[fries_df['Item Name'] == 'LOADED FRIES']\n",
    "loaded_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_fries = fries_df[fries_df['Item Name'].str.lower().str.contains('loaded')]\n",
    "loaded_fries['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_fries['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_fries[(loaded_fries['Item Variation'] == 'Truffle Salt') | (loaded_fries['Item Variation'] == 'Rosemary Pepper')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392",
   "metadata": {},
   "source": [
    "There were changes made to the fries offered by the restaurant:\n",
    "* There was one order with Item name `LOAD YOUR FRIES`. This is a mistake.\n",
    "    * This item is no longer on the menu.\n",
    "* `French fries` were only listed on one day with **two** orders.\n",
    "* `Wings & Fries` is a recent addition, from **Februrary 9th, 2025**, and is still part of the menu.\n",
    "* `LOADED FRIES` are still on the menu and have been since **March 5th, 2024**.\n",
    "* `CRISPY FRIES` were added to the menu on **May 6th, 2025**.\n",
    "    * They replaced `CRINKLE FRIES`, which are not in the catalog and have a *maximum order date* of **May 6th, 2025**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393",
   "metadata": {},
   "source": [
    "### Ribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rib items\n",
    "\n",
    "rib_df = df.dropna(subset=['Item Name'])\n",
    "rib_df = rib_df[rib_df['Item Name'].str.lower().str.contains('rib')]\n",
    "rib_df['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ribs category in catalog\n",
    "\n",
    "items_df[items_df['category'] == 'RIBS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396",
   "metadata": {},
   "source": [
    "#### Pork Ribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get orders of pork ribs\n",
    "\n",
    "pork_rib_aliases = ['GLAZED BABY BACK PORK RIBS', 'BABY BACK PORK RIBS', 'Get your baby back Pork Ribs']\n",
    "pork_ribs_df = rib_df[rib_df['Item Name'].isin(pork_rib_aliases)]\n",
    "pork_ribs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List variations for pork ribs\n",
    "\n",
    "pork_ribs_df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399",
   "metadata": {},
   "source": [
    "#### Beef Ribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beef Ribs\n",
    "\n",
    "beef_rib_aliases = ['BEEF BACK RIBS (Full Rack)', 'BEEF SHORT RIB', 'SHORT RIB PLATTER', 'BEEF SHORT RIB (Full Rack)', 'Beef Short Rib', 'Party Package !BEEF RIBS ONLY! (4-6 ppl)', 'RIBS & WINGS BUNDLE !BEEF RIBS ONLY!', 'BEEF SHORT RIBS (FULL RACK)', 'Beef Back Ribs (Full Rack)', 'BEEF BACK RIBS (FULL RACK)']\n",
    "beef_rib_df = rib_df[rib_df['Item Name'].isin(beef_rib_aliases)]\n",
    "beef_rib_df['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List variations for beef rib orders\n",
    "\n",
    "beef_rib_df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402",
   "metadata": {},
   "outputs": [],
   "source": [
    "beef_rib_df[beef_rib_df['Item Name'] == 'Beef Short Rib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get beef items from catalog\n",
    "\n",
    "items_beef = items_df[items_df['Item Name'].str.lower().str.contains('beef')]\n",
    "items_beef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for orders of dino ribs\n",
    "\n",
    "dino_df = df.dropna(subset='Item Name')\n",
    "dino_df = dino_df[dino_df['Item Name'].str.lower().str.contains('dino')]\n",
    "\n",
    "dino_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if only dino dinner or if also dino ribs\n",
    "\n",
    "dino_df['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406",
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407",
   "metadata": {},
   "source": [
    "## Item Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See list of possible item variations\n",
    "\n",
    "df['Item Variation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique sides offered: {len(df[df['Item Variation'] == 'Side']['Item Name'].unique())}\")\n",
    "print(f\"Unique sides: {df[df['Item Variation'] == 'Side']['Item Name'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Truffle Salt']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Rosemary Pepper']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == '6 pcs']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See number of orders per method of spelling Mac & Cheese\n",
    "\n",
    "mac_and_cheese_variations = ['ARTISAN MAC AND CHEESE', 'MAC&CHEESE', 'Artisan Mac and Cheese']\n",
    "\n",
    "variant_counts = {}\n",
    "\n",
    "for variant in mac_and_cheese_variations:\n",
    "    variant_counts[variant] = len(df[df['Item Name'] == variant])\n",
    "\n",
    "variant_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Name'] == 'Artisan Mac and Cheese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See variations of Mac & Cheese ordered\n",
    "\n",
    "df[df['Item Name'].isin(mac_and_cheese_variations)]['Item Variation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See variations of Pineapple Slaw ordered\n",
    "\n",
    "df[df['Item Name'] == 'PINEAPPLE SLAW']['Item Variation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Full Rack'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Full Rack']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Full'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Variation'] == 'Full']['Item Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_items = df[df['Item Variation'] == 'Regular']\n",
    "regular_items['Item Name'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_items['Item Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Name'] == 'BEEF BACK RIBS (FULL RACK)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Name'] == 'Beef Back Ribs (Full Rack)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425",
   "metadata": {},
   "source": [
    "* `Item Name` and `Item Variations` have duplicate entries with variations in spelling.\n",
    "    * Mac & Cheese has **three** different spellings: `ARTISAN MAC AND CHEESE`, `MAC&CHEESE`, `Artisan Mac and Cheese`\n",
    "    * A full rack of beef back ribs has **two** different spellings: `Beef Back Ribs (Full Rack)`, and `BEEF BACK RIBS (FULL RACK)`\n",
    "        * Both orders are from `DOORDASH` so that can't explain the difference.\n",
    "    * There are **four** different spellings for Baby back pork ribs: `GLAZED BABY BACK PORK RIBS`, `BABY BACK PORK RIBS`, `GET YOUR BABY BACK!`, and `\"Get your baby back\" Pork Ribs`.\n",
    "* Side items, such as the Mac & Cheese and slaw can have `Item Variation` set to `Full`, `Side`, or `8oz`.\n",
    "* `Item Variation` `Regular` seems to imply to not apply any variations.\n",
    "    * `Full Rack` relates to orders of pork ribs.\n",
    "    * `Side`, `Full`, and `8oz` relate to orders of sides.\n",
    "    * Values with `pcs` relate to items that come in multiples such as Chicken Wings and Mozzarella Sticks\n",
    "    * Seasoning variations such as `Rosemary Pepper` and `Truffle Salt` relate to orders of fries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426",
   "metadata": {},
   "source": [
    "## Top-selling Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427",
   "metadata": {},
   "source": [
    "### Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect quantity of items and their variations ordered\n",
    "\n",
    "item_variation_counts = df.groupby(by=['Item Name', 'Item Variation']).size().sort_values(ascending=False).reset_index(name='count')\n",
    "\n",
    "item_variation_counts.to_csv(REPORTS_DIR / 'item_variation_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect quantity of items ordered\n",
    "\n",
    "item_counts = df.groupby(by='Item Name').size().sort_values(ascending=False).reset_index(name='count')\n",
    "\n",
    "item_counts.to_csv(REPORTS_DIR / 'item_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See top 10 performing items\n",
    "\n",
    "item_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See top 10 performing items and their variations\n",
    "\n",
    "item_variation_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See bottom 10 performing items\n",
    "\n",
    "item_counts.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See bottom 10 performing items and their variations\n",
    "\n",
    "item_variation_counts.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434",
   "metadata": {},
   "source": [
    "### Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Item Quantity'] > 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List top 10 performing items based on revenue\n",
    "\n",
    "item_revenues = df.groupby(by='Item Name')['Item Total Price'].sum().sort_values(ascending=False).reset_index(name='total_revenue')\n",
    "item_revenues.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List top 10 performing items and their variations based on revenue\n",
    "\n",
    "item_combination_revenues = df.groupby(by=['Item Name', 'Item Variation'])['Item Total Price'].sum().sort_values(ascending=False).reset_index(name='total_revenue')\n",
    "item_combination_revenues.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List worst 10 performing items based on revenue\n",
    "\n",
    "item_revenues.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List items with zero revenue\n",
    "\n",
    "item_revenues[item_revenues['total_revenue'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440",
   "metadata": {},
   "source": [
    "Condiments provide **zero** revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List worst 10 performing items and their variations based on revenue\n",
    "\n",
    "item_combination_revenues[item_combination_revenues['total_revenue'] > 0].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442",
   "metadata": {},
   "source": [
    "* Items ranked by revenue:\n",
    "    1. `GLAZED BABY BACK PORK RIBS`: **$16,092.10**\n",
    "    2. `BEEF BACK RIBS (Full Rack)`: **$11,299.39**\n",
    "    3. `STEAK SANDWICH COMBO`: **$6,297.93**\n",
    "* Items and variations ranked by revenue:\n",
    "    1. Full Rack of Glazed Baby Back Pork Ribs: **$12,391.97**\n",
    "    2. Regular order of Beef Back Ribs (Full Rack): **$11,299.39**\n",
    "    3. Regular order of Steak Sandwich Combo: **$6297.93**\n",
    "* Items ranked lowest by revenue:\n",
    "    1. `Pickled Jalapenos (8oz)`: **$1.64**\n",
    "    2. `BLUE CHEESE SAUCE`: **$2.05**\n",
    "    3. `BBQ dipping sauce`: **$2.55**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443",
   "metadata": {},
   "source": [
    "# Revenue & Payments\n",
    "\n",
    "- [x] Total Sales, average order value, median order value.\n",
    "- [x] Check for chargebacks/refunds and their impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444",
   "metadata": {},
   "source": [
    "## Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with order-level information\n",
    "\n",
    "orders_df = df.groupby(by='pseudo_order_id').agg({\n",
    "    'Order Total': 'first',\n",
    "    'Order Refunded Amount': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total sales\n",
    "\n",
    "print(f\"Total Sales: {orders_df['Order Total'].sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for Order Total\n",
    "\n",
    "orders_df['Order Total'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* There were a total of **1,432** orders since opening.\n",
    "* Total Sales = **$90,341.63**\n",
    "* Average Sale Amount = **$63.08**\n",
    "* Median Sale Amount = **$50.44**\n",
    "* Maximum Sale Amount = **$1,158.75**\n",
    "* Minimum Sale Amount = **$1.00**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450",
   "metadata": {},
   "source": [
    "## Refunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for order refunded amount\n",
    "\n",
    "orders_df['Order Refunded Amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* All values in `Order Refunded Amount` are **NaN**.\n",
    "* This either means that there were no refunded orders, or that this information is not tracked in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454",
   "metadata": {},
   "source": [
    "***Data Quality Checks***\n",
    "\n",
    "- Columns `Currency`, `Order Shipping Price`, `Order Refunded Amount`, `Fulfillment Location`, `Recipient Region`, and `Item SKU` carry no valuabe information and can be dropped from the dataset.\n",
    "- Geographic details such as `Address`, `Postal Code`, `City`, `Region` are missing greater than **87%** of entries.\n",
    "\n",
    "**Business Logic Validation**\n",
    "* Outliers in `Item Price` are catering packages, platters, bundles, and combos.\n",
    "* There are **no** refunded orders.\n",
    "    * There were **6** cancelled orders.\n",
    "* **1,073** rows are missing Fulfillment data.\n",
    "\n",
    "**Customer-Level Insights**\n",
    "* **822** unique customers.\n",
    "* **11%** of customers are repeat customers (have ordered more than once).\n",
    "    * **60%** of repeat customers order at most **2** times.\n",
    "    * The *average number of days* between repeat orers is **54.2 days**.\n",
    "    * The *median number of days* between repeat orders if **35 days**.\n",
    "\n",
    "**Time-Based Patterns**\n",
    "* **Fridays** have the highest number of orders.\n",
    "    * **Tuesdays** are the second most popular days.\n",
    "    * Other days of the week have similar *mean* and *median* order quantities.\n",
    "* Peak order time is around **7pm**.\n",
    "\n",
    "**Menu and Product-Level Insights**\n",
    "* **135** unique combinations of items and their variations have been sold.\n",
    "* Menu item names need to be standardized.\n",
    "* `Item Variation` applies to both main and side dishes.\n",
    "    * Can't be used as a *category* feature.\n",
    "* Baby Back Pork Ribs is the **most ordered** item and provides the **highest revenue**.\n",
    "* Some items have very low sales and need further exploration.\n",
    "\n",
    "**Revenue & Payments**\n",
    "* Total Sales: **$90,341.63**\n",
    "* Average Order Amount: **$63.08**\n",
    "* Median Order Amount: **$50.44**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belly_rubb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
